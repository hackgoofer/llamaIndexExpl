{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying LlamaIndex Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out the best way to grab the doc structure -- Decision: Use Sphinx/Doctree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Sphinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pickle\n",
    "\n",
    "def read_doctree(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<document source=\"/Users/sasha/github/LlamaIndex/llama_index/docs/getting_started/installation.md\"><section ids=\"installation-and-setup\" myst-anchor=\"getting_started/installation.md#installation-and-setup\" names=\"installation\\ and\\ setup\"><title>Installation and Setup</title><section ids=\"installation-from-pip\" myst-anchor=\"getting_started/installation.md#installation-from-pip\" names=\"installation\\ from\\ pip\"><title>Installation from Pip</title><paragraph>Install from pip:</paragraph><literal_block language=\"default\" xml:space=\"preserve\">pip install llama-index\n",
      "</literal_block><paragraph><strong>NOTE:</strong> LlamaIndex may download and store local files for various packages (NLTK, HuggingFace, ‚Ä¶). Use the environment variable ‚ÄúLLAMA_INDEX_CACHE_DIR‚Äù to control where these files are saved.</paragraph><paragraph>If you prefer to install from source, see below.</paragraph></section><section ids=\"important-openai-environment-setup\" myst-anchor=\"getting_started/installation.md#important-openai-environment-setup\" names=\"important:\\ openai\\ environment\\ setup\"><title>Important: OpenAI Environment Setup</title><paragraph>By default, we use the OpenAI <literal>gpt-3.5-turbo</literal> model for text generation and <literal>text-embedding-ada-002</literal> for retrieval and embeddings. In order to use this, you must have an OPENAI_API_KEY set up as an environment variable.\n",
      "You can obtain an API key by logging into your OpenAI account and <reference refuri=\"https://platform.openai.com/account/api-keys\">and creating a new API key</reference>.</paragraph><tip><paragraph>You can also <pending_xref refdoc=\"getting_started/installation\" refdomain=\"True\" refexplicit=\"True\" reftarget=\"/module_guides/models/llms/usage_custom.md\" reftype=\"myst\" refwarn=\"True\"><inline classes=\"xref myst\">use one of many other available LLMs</inline></pending_xref>. You may\n",
      "need additional environment keys + tokens setup depending on the LLM provider.</paragraph></tip></section><section ids=\"local-model-setup\" myst-anchor=\"getting_started/installation.md#local-model-setup\" names=\"local\\ model\\ setup\"><title>Local Model Setup</title><paragraph>If you don‚Äôt wish to use OpenAI, consider setting up a local LLM and embedding model in the service context.</paragraph><paragraph>A full guide to using and configuring LLMs available <pending_xref refdoc=\"getting_started/installation\" refdomain=\"True\" refexplicit=\"True\" reftarget=\"/module_guides/models/llms.md\" reftype=\"myst\" refwarn=\"True\"><inline classes=\"xref myst\">here</inline></pending_xref>.</paragraph><paragraph>A full guide to using and configuring embedding models is available <pending_xref refdoc=\"getting_started/installation\" refdomain=\"True\" refexplicit=\"True\" reftarget=\"/module_guides/models/embeddings.md\" reftype=\"myst\" refwarn=\"True\"><inline classes=\"xref myst\">here</inline></pending_xref>.</paragraph></section><section ids=\"installation-from-source\" myst-anchor=\"getting_started/installation.md#installation-from-source\" names=\"installation\\ from\\ source\"><title>Installation from Source</title><paragraph>Git clone this repository: <literal>git clone https://github.com/jerryjliu/llama_index.git</literal>. Then do the following:</paragraph><bullet_list bullet=\"-\"><list_item><paragraph><reference refuri=\"https://python-poetry.org/docs/#installation\">Install poetry</reference> - this will help you manage package dependencies</paragraph></list_item><list_item><paragraph><literal>poetry shell</literal> - this command creates a virtual environment, which keeps installed packages contained to this project</paragraph></list_item><list_item><paragraph><literal>poetry install</literal> - this will install the core package requirements</paragraph></list_item><list_item><paragraph>(Optional) <literal>poetry install --with dev,docs</literal> - this will install all dependencies needed for most local development</paragraph></list_item></bullet_list></section><section ids=\"optional-dependencies\" myst-anchor=\"getting_started/installation.md#optional-dependencies\" names=\"optional\\ dependencies\"><title>Optional Dependencies</title><paragraph>By default LlamaIndex installs a core set of dependencies; we also provide a convenient way to install commonly-required optional dependencies. These are currently in three sets:</paragraph><bullet_list bullet=\"-\"><list_item><paragraph><literal>pip install llama-index[local_models]</literal> installs tools useful for private LLMs, local inference, and HuggingFace models</paragraph></list_item><list_item><paragraph><literal>pip install llama-index[postgres]</literal> is useful if you are working with Postgres, PGVector or Supabase</paragraph></list_item><list_item><paragraph><literal>pip install llama-index[query_tools]</literal> gives you tools for hybrid search, structured outputs, and node post-processing</paragraph></list_item></bullet_list></section></section></document>\n"
     ]
    }
   ],
   "source": [
    "# Replace 'path_to_doctree_file.doctree' with your .doctree file path\n",
    "# doctree = read_doctree('/Users/sasha/github/LlamaIndex/llama_index/docs/_build/doctrees/index.doctree')\n",
    "# agentic_strategies_doctree = read_doctree('/Users/sasha/github/LlamaIndex/llama_index/docs/_build/doctrees/optimizing/advanced_retrieval/advanced_retrieval.doctree')\n",
    "installation_doctree = read_doctree('/Users/sasha/github/LlamaIndex/llama_index/docs/_build/doctrees/getting_started/installation.doctree')\n",
    "# print(doctree)\n",
    "# print(agentic_strategies_doctree)\n",
    "print(installation_doctree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<class 'docutils.nodes.section'>, <class 'docutils.nodes.system_message'>, <class 'docutils.nodes.target'>, <class 'sphinx.addnodes.desc_signature'>, <class 'docutils.nodes.problematic'>}\n",
      "\n",
      "Examples for <class 'docutils.nodes.section'>:\n",
      "<section ids=\"welcome-to-llamaindex\" names=\"welcome\\ to\\ llamaindex\\ ü¶ô\\ !\"><title>Welcome to LlamaIndex ü¶ô !</title><paragraph>LlamaIndex is a data framework for <reference name=\"LLM\" refuri=\"https://en.wikipedia.org/wiki/Large_language_model\">LLM</reference><target ids=\"['llm']\" names=\"['llm']\" refuri=\"https://en.wikipedia.org/wiki/Large_language_model\"/>-based applications to ingest, structure, and access private or domain-specific data. It‚Äôs available in Python (these docs) and <reference name=\"Typescript\" refuri=\"https://ts.llamaindex.ai/\">Typescript</reference><target ids=\"['typescript']\" names=\"['typescript']\" refuri=\"https://ts.llamaindex.ai/\"/>.</paragraph><section ids=\"why-llamaindex\" names=\"üöÄ\\ why\\ llamaindex?\"><title>üöÄ Why LlamaIndex?</title><paragraph>LLMs offer a natural language interface between humans and data. Widely available models come pre-trained on huge amounts of publicly available data like Wikipedia, mailing lists, textbooks, source code and more.</paragraph><paragraph>However, while LLMs are trained on a great deal of data, they are not trained on <strong>your</strong> data, which may be private or specific to the problem you‚Äôre trying to solve. It‚Äôs behind APIs, in SQL databases, or trapped in PDFs and slide decks.</paragraph><paragraph>You may choose to <strong>fine-tune</strong> a LLM with your data, but:</paragraph><bullet_list bullet=\"-\"><list_item><paragraph>Training a LLM is <strong>expensive</strong>.</paragraph></list_item><list_item><paragraph>Due to the cost to train, it‚Äôs <strong>hard to update</strong> a LLM with latest information.</paragraph></list_item><list_item><paragraph><strong>Observability</strong> is lacking. When you ask a LLM a question, it‚Äôs not obvious how the LLM arrived at its answer.</paragraph></list_item></bullet_list><paragraph>LlamaIndex takes a different approach called <reference name=\"Retrieval-Augmented Generation (RAG)\" refuri=\"./getting_started/concepts.html\">Retrieval-Augmented Generation (RAG)</reference><target ids=\"['retrieval-augmented-generation-rag']\" names=\"['retrieval-augmented generation (rag)']\" refuri=\"./getting_started/concepts.html\"/>. Instead of asking LLM to generate an answer immediately, LlamaIndex:</paragraph><enumerated_list enumtype=\"arabic\" prefix=\"\" suffix=\".\"><list_item><paragraph>retrieves information from your data sources first,</paragraph></list_item><list_item><paragraph>adds it to your question as context, and</paragraph></list_item><list_item><paragraph>asks the LLM to answer based on the enriched prompt.</paragraph></list_item></enumerated_list><paragraph>RAG overcomes all three weaknesses of the fine-tuning approach:</paragraph><bullet_list bullet=\"-\"><list_item><paragraph>There‚Äôs no training involved, so it‚Äôs <strong>cheap</strong>.</paragraph></list_item><list_item><paragraph>Data is fetched only when you ask for them, so it‚Äôs <strong>always up to date</strong>.</paragraph></list_item><list_item><paragraph>LlamaIndex can show you the retrieved documents, so it‚Äôs <strong>more trustworthy</strong>.</paragraph></list_item></bullet_list><paragraph>LlamaIndex imposes no restriction on how you use LLMs. You can still use LLMs as auto-complete, chatbots, semi-autonomous agents, and more (see Use Cases on the left). It only makes LLMs more relevant to you.</paragraph></section><section ids=\"how-can-llamaindex-help\" names=\"ü¶ô\\ how\\ can\\ llamaindex\\ help?\"><title>ü¶ô How can LlamaIndex help?</title><paragraph>LlamaIndex provides the following tools:</paragraph><bullet_list bullet=\"-\"><list_item><paragraph><strong>Data connectors</strong> ingest your existing data from their native source and format. These could be APIs, PDFs, SQL, and (much) more.</paragraph></list_item><list_item><paragraph><strong>Data indexes</strong> structure your data in intermediate representations that are easy and performant for LLMs to consume.</paragraph></list_item><list_item><paragraph><strong>Engines</strong> provide natural language access to your data. For example:</paragraph><bullet_list bullet=\"-\"><list_item><paragraph>Query engines are powerful retrieval interfaces for knowledge-augmented output.</paragraph></list_item><list_item><paragraph>Chat engines are conversational interfaces for multi-message, ‚Äúback and forth‚Äù interactions with your data.</paragraph></list_item></bullet_list></list_item><list_item><paragraph><strong>Data agents</strong> are LLM-powered knowledge workers augmented by tools, from simple helper functions to API integrations and more.</paragraph></list_item><list_item><paragraph><strong>Application integrations</strong> tie LlamaIndex back into the rest of your ecosystem. This could be LangChain, Flask, Docker, ChatGPT, or‚Ä¶ anything else!</paragraph></list_item></bullet_list></section><section ids=\"who-is-llamaindex-for\" names=\"üë®‚Äçüë©‚Äçüëß‚Äçüë¶\\ who\\ is\\ llamaindex\\ for?\"><title>üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Who is LlamaIndex for?</title><paragraph>LlamaIndex provides tools for beginners, advanced users, and everyone in between.</paragraph><paragraph>Our high-level API allows beginner users to use LlamaIndex to ingest and query their data in 5 lines of code.</paragraph><paragraph>For more complex applications, our lower-level APIs allow advanced users to customize and extend any module‚Äîdata connectors, indices, retrievers, query engines, reranking modules‚Äîto fit their needs.</paragraph></section><section ids=\"getting-started\" names=\"getting\\ started\"><title>Getting Started</title><paragraph>To install the library:</paragraph><paragraph><literal>pip install llama-index</literal></paragraph><paragraph>We recommend starting at <reference name=\"how to read these docs\" refuri=\"./getting_started/reading.html\">how to read these docs</reference><target ids=\"['how-to-read-these-docs']\" names=\"['how to read these docs']\" refuri=\"./getting_started/reading.html\"/>, which will point you to the right place based on your experience level.</paragraph></section><section ids=\"ecosystem\" names=\"üó∫Ô∏è\\ ecosystem\"><title>üó∫Ô∏è Ecosystem</title><paragraph>To download or contribute, find LlamaIndex on:</paragraph><bullet_list bullet=\"-\"><list_item><paragraph>Github: <reference refuri=\"https://github.com/jerryjliu/llama_index\">https://github.com/jerryjliu/llama_index</reference></paragraph></list_item><list_item><paragraph>PyPi:</paragraph><bullet_list bullet=\"-\"><list_item><paragraph>LlamaIndex: <reference refuri=\"https://pypi.org/project/llama-index/\">https://pypi.org/project/llama-index/</reference>.</paragraph></list_item><list_item><paragraph>GPT Index (duplicate): <reference refuri=\"https://pypi.org/project/gpt-index/\">https://pypi.org/project/gpt-index/</reference>.</paragraph></list_item></bullet_list></list_item><list_item><definition_list><definition_list_item><term>NPM (Typescript/Javascript):</term><definition><bullet_list bullet=\"-\"><list_item><paragraph>Github: <reference refuri=\"https://github.com/run-llama/LlamaIndexTS\">https://github.com/run-llama/LlamaIndexTS</reference></paragraph></list_item><list_item><paragraph>Docs: <reference refuri=\"https://ts.llamaindex.ai/\">https://ts.llamaindex.ai/</reference></paragraph></list_item><list_item><paragraph>LlamaIndex.TS: <reference refuri=\"https://www.npmjs.com/package/llamaindex\">https://www.npmjs.com/package/llamaindex</reference></paragraph></list_item></bullet_list></definition></definition_list_item></definition_list></list_item></bullet_list><section ids=\"community\" names=\"community\"><title>Community</title><paragraph>Need help? Have a feature suggestion? Join the LlamaIndex community:</paragraph><bullet_list bullet=\"-\"><list_item><paragraph>Twitter: <reference refuri=\"https://twitter.com/llama_index\">https://twitter.com/llama_index</reference></paragraph></list_item><list_item><paragraph>Discord <reference refuri=\"https://discord.gg/dGcwcsnxhU\">https://discord.gg/dGcwcsnxhU</reference></paragraph></list_item></bullet_list></section><section ids=\"associated-projects\" names=\"associated\\ projects\"><title>Associated projects</title><bullet_list bullet=\"-\"><list_item><paragraph>üè° LlamaHub: <reference refuri=\"https://llamahub.ai\">https://llamahub.ai</reference> | A large (and growing!) collection of custom data connectors</paragraph></list_item><list_item><paragraph>üß™ LlamaLab: <reference refuri=\"https://github.com/run-llama/llama-lab\">https://github.com/run-llama/llama-lab</reference> | Ambitious projects built on top of LlamaIndex</paragraph></list_item></bullet_list><compound classes=\"toctree-wrapper\"><toctree caption=\"Getting Started\" entries=\"[(None, 'getting_started/installation'), (None, 'getting_started/reading'), (None, 'getting_started/starter_example'), (None, 'getting_started/concepts'), (None, 'getting_started/customization'), (None, 'getting_started/discover_llamaindex')]\" glob=\"False\" hidden=\"True\" includefiles=\"['getting_started/installation', 'getting_started/reading', 'getting_started/starter_example', 'getting_started/concepts', 'getting_started/customization', 'getting_started/discover_llamaindex']\" includehidden=\"False\" maxdepth=\"1\" numbered=\"0\" parent=\"index\" rawcaption=\"Getting Started\" rawentries=\"[]\" titlesonly=\"False\"/></compound><compound classes=\"toctree-wrapper\"><toctree caption=\"Use Cases\" entries=\"[(None, 'use_cases/q_and_a'), (None, 'use_cases/chatbots'), (None, 'use_cases/agents'), (None, 'use_cases/extraction'), (None, 'use_cases/multimodal')]\" glob=\"False\" hidden=\"True\" includefiles=\"['use_cases/q_and_a', 'use_cases/chatbots', 'use_cases/agents', 'use_cases/extraction', 'use_cases/multimodal']\" includehidden=\"False\" maxdepth=\"2\" numbered=\"0\" parent=\"index\" rawcaption=\"Use Cases\" rawentries=\"[]\" titlesonly=\"False\"/></compound><compound classes=\"toctree-wrapper\"><toctree caption=\"Understanding\" entries=\"[(None, 'understanding/understanding'), (None, 'understanding/using_llms/using_llms'), (None, 'understanding/loading/loading'), (None, 'understanding/indexing/indexing'), (None, 'understanding/storing/storing'), (None, 'understanding/querying/querying'), (None, 'understanding/putting_it_all_together/putting_it_all_together'), (None, 'understanding/tracing_and_debugging/tracing_and_debugging'), (None, 'understanding/evaluating/evaluating')]\" glob=\"False\" hidden=\"True\" includefiles=\"['understanding/understanding', 'understanding/using_llms/using_llms', 'understanding/loading/loading', 'understanding/indexing/indexing', 'understanding/storing/storing', 'understanding/querying/querying', 'understanding/putting_it_all_together/putting_it_all_together', 'understanding/tracing_and_debugging/tracing_and_debugging', 'understanding/evaluating/evaluating']\" includehidden=\"False\" maxdepth=\"2\" numbered=\"0\" parent=\"index\" rawcaption=\"Understanding\" rawentries=\"[]\" titlesonly=\"False\"/></compound><compound classes=\"toctree-wrapper\"><toctree caption=\"Optimizing\" entries=\"[(None, 'optimizing/basic_strategies/basic_strategies'), (None, 'optimizing/advanced_retrieval/advanced_retrieval'), (None, 'optimizing/agentic_strategies/agentic_strategies'), (None, 'optimizing/evaluation/evaluation'), (None, 'optimizing/fine-tuning/fine-tuning'), (None, 'optimizing/production_rag'), (None, 'optimizing/building_rag_from_scratch')]\" glob=\"False\" hidden=\"True\" includefiles=\"['optimizing/basic_strategies/basic_strategies', 'optimizing/advanced_retrieval/advanced_retrieval', 'optimizing/agentic_strategies/agentic_strategies', 'optimizing/evaluation/evaluation', 'optimizing/fine-tuning/fine-tuning', 'optimizing/production_rag', 'optimizing/building_rag_from_scratch']\" includehidden=\"False\" maxdepth=\"2\" numbered=\"0\" parent=\"index\" rawcaption=\"Optimizing\" rawentries=\"[]\" titlesonly=\"False\"/></compound><compound classes=\"toctree-wrapper\"><toctree caption=\"Module Guides\" entries=\"[(None, 'module_guides/models/models'), (None, 'module_guides/models/prompts'), (None, 'module_guides/loading/loading'), (None, 'module_guides/indexing/indexing'), (None, 'module_guides/storing/storing'), (None, 'module_guides/querying/querying'), (None, 'module_guides/observability/observability'), (None, 'module_guides/evaluating/root'), (None, 'module_guides/supporting_modules/supporting_modules')]\" glob=\"False\" hidden=\"True\" includefiles=\"['module_guides/models/models', 'module_guides/models/prompts', 'module_guides/loading/loading', 'module_guides/indexing/indexing', 'module_guides/storing/storing', 'module_guides/querying/querying', 'module_guides/observability/observability', 'module_guides/evaluating/root', 'module_guides/supporting_modules/supporting_modules']\" includehidden=\"False\" maxdepth=\"2\" numbered=\"0\" parent=\"index\" rawcaption=\"Module Guides\" rawentries=\"[]\" titlesonly=\"False\"/></compound><compound classes=\"toctree-wrapper\"><toctree caption=\"API Reference\" entries=\"[(None, 'api_reference/index')]\" glob=\"False\" hidden=\"True\" includefiles=\"['api_reference/index']\" includehidden=\"False\" maxdepth=\"1\" numbered=\"0\" parent=\"index\" rawcaption=\"API Reference\" rawentries=\"[]\" titlesonly=\"False\"/></compound><compound classes=\"toctree-wrapper\"><toctree caption=\"Community\" entries=\"[(None, 'community/integrations'), (None, 'community/frequently_asked_questions'), (None, 'community/full_stack_projects')]\" glob=\"False\" hidden=\"True\" includefiles=\"['community/integrations', 'community/frequently_asked_questions', 'community/full_stack_projects']\" includehidden=\"False\" maxdepth=\"2\" numbered=\"0\" parent=\"index\" rawcaption=\"Community\" rawentries=\"[]\" titlesonly=\"False\"/></compound><compound classes=\"toctree-wrapper\"><toctree caption=\"Contributing\" entries=\"[(None, 'contributing/contributing'), (None, 'contributing/documentation')]\" glob=\"False\" hidden=\"True\" includefiles=\"['contributing/contributing', 'contributing/documentation']\" includehidden=\"False\" maxdepth=\"2\" numbered=\"0\" parent=\"index\" rawcaption=\"Contributing\" rawentries=\"[]\" titlesonly=\"False\"/></compound><compound classes=\"toctree-wrapper\"><toctree caption=\"Changes\" entries=\"[(None, 'changes/changelog'), (None, 'changes/deprecated_terms')]\" glob=\"False\" hidden=\"True\" includefiles=\"['changes/changelog', 'changes/deprecated_terms']\" includehidden=\"False\" maxdepth=\"2\" numbered=\"0\" parent=\"index\" rawcaption=\"Changes\" rawentries=\"[]\" titlesonly=\"False\"/></compound></section></section></section>\n",
      "\n",
      "Examples for <class 'docutils.nodes.target'>:\n",
      "<target ids=\"['llm']\" names=\"['llm']\" refuri=\"https://en.wikipedia.org/wiki/Large_language_model\"/>\n",
      "\n",
      "Examples for <class 'sphinx.addnodes.desc_signature'>:\n",
      "<desc_signature _toc_name=\"CohereRerankerFinetuneEngine\" _toc_parts=\"('llama_index.finetuning', 'CohereRerankerFinetuneEngine')\" class=\"\" classes=\"sig sig-object\" fullname=\"CohereRerankerFinetuneEngine\" ids=\"llama_index.finetuning.CohereRerankerFinetuneEngine\" module=\"llama_index.finetuning\"><desc_annotation xml:space=\"preserve\">class<desc_sig_space classes=\"w\"> </desc_sig_space></desc_annotation><desc_addname classes=\"sig-prename descclassname\" xml:space=\"preserve\">llama_index.finetuning.</desc_addname><desc_name classes=\"sig-name descname\" xml:space=\"preserve\">CohereRerankerFinetuneEngine</desc_name><desc_parameterlist xml:space=\"preserve\"><desc_parameter xml:space=\"preserve\"><desc_sig_name classes=\"n\">train_file_name</desc_sig_name><desc_sig_punctuation classes=\"p\">:</desc_sig_punctuation><desc_sig_space classes=\"w\"> </desc_sig_space><desc_sig_name classes=\"n\"><pending_xref py:class=\"True\" py:module=\"llama_index.finetuning\" refdomain=\"py\" refspecific=\"False\" reftarget=\"str\" reftype=\"class\">str</pending_xref></desc_sig_name><desc_sig_space classes=\"w\"> </desc_sig_space><desc_sig_operator classes=\"o\">=</desc_sig_operator><desc_sig_space classes=\"w\"> </desc_sig_space><inline classes=\"default_value\" support_smartquotes=\"False\">'train.jsonl'</inline></desc_parameter><desc_parameter xml:space=\"preserve\"><desc_sig_name classes=\"n\">val_file_name</desc_sig_name><desc_sig_punctuation classes=\"p\">:</desc_sig_punctuation><desc_sig_space classes=\"w\"> </desc_sig_space><desc_sig_name classes=\"n\"><pending_xref py:class=\"True\" py:module=\"llama_index.finetuning\" refdomain=\"py\" refspecific=\"False\" reftarget=\"typing.Optional\" reftype=\"obj\">Optional</pending_xref><desc_sig_punctuation classes=\"p\">[</desc_sig_punctuation><pending_xref py:class=\"True\" py:module=\"llama_index.finetuning\" refdomain=\"py\" refspecific=\"False\" reftarget=\"str\" reftype=\"class\">str</pending_xref><desc_sig_punctuation classes=\"p\">]</desc_sig_punctuation></desc_sig_name><desc_sig_space classes=\"w\"> </desc_sig_space><desc_sig_operator classes=\"o\">=</desc_sig_operator><desc_sig_space classes=\"w\"> </desc_sig_space><inline classes=\"default_value\" support_smartquotes=\"False\">None</inline></desc_parameter><desc_parameter xml:space=\"preserve\"><desc_sig_name classes=\"n\">model_name</desc_sig_name><desc_sig_punctuation classes=\"p\">:</desc_sig_punctuation><desc_sig_space classes=\"w\"> </desc_sig_space><desc_sig_name classes=\"n\"><pending_xref py:class=\"True\" py:module=\"llama_index.finetuning\" refdomain=\"py\" refspecific=\"False\" reftarget=\"str\" reftype=\"class\">str</pending_xref></desc_sig_name><desc_sig_space classes=\"w\"> </desc_sig_space><desc_sig_operator classes=\"o\">=</desc_sig_operator><desc_sig_space classes=\"w\"> </desc_sig_space><inline classes=\"default_value\" support_smartquotes=\"False\">'exp_finetune'</inline></desc_parameter><desc_parameter xml:space=\"preserve\"><desc_sig_name classes=\"n\">model_type</desc_sig_name><desc_sig_punctuation classes=\"p\">:</desc_sig_punctuation><desc_sig_space classes=\"w\"> </desc_sig_space><desc_sig_name classes=\"n\"><pending_xref py:class=\"True\" py:module=\"llama_index.finetuning\" refdomain=\"py\" refspecific=\"False\" reftarget=\"str\" reftype=\"class\">str</pending_xref></desc_sig_name><desc_sig_space classes=\"w\"> </desc_sig_space><desc_sig_operator classes=\"o\">=</desc_sig_operator><desc_sig_space classes=\"w\"> </desc_sig_space><inline classes=\"default_value\" support_smartquotes=\"False\">'RERANK'</inline></desc_parameter><desc_parameter xml:space=\"preserve\"><desc_sig_name classes=\"n\">base_model</desc_sig_name><desc_sig_punctuation classes=\"p\">:</desc_sig_punctuation><desc_sig_space classes=\"w\"> </desc_sig_space><desc_sig_name classes=\"n\"><pending_xref py:class=\"True\" py:module=\"llama_index.finetuning\" refdomain=\"py\" refspecific=\"False\" reftarget=\"str\" reftype=\"class\">str</pending_xref></desc_sig_name><desc_sig_space classes=\"w\"> </desc_sig_space><desc_sig_operator classes=\"o\">=</desc_sig_operator><desc_sig_space classes=\"w\"> </desc_sig_space><inline classes=\"default_value\" support_smartquotes=\"False\">'english'</inline></desc_parameter><desc_parameter xml:space=\"preserve\"><desc_sig_name classes=\"n\">api_key</desc_sig_name><desc_sig_punctuation classes=\"p\">:</desc_sig_punctuation><desc_sig_space classes=\"w\"> </desc_sig_space><desc_sig_name classes=\"n\"><pending_xref py:class=\"True\" py:module=\"llama_index.finetuning\" refdomain=\"py\" refspecific=\"False\" reftarget=\"typing.Optional\" reftype=\"obj\">Optional</pending_xref><desc_sig_punctuation classes=\"p\">[</desc_sig_punctuation><pending_xref py:class=\"True\" py:module=\"llama_index.finetuning\" refdomain=\"py\" refspecific=\"False\" reftarget=\"str\" reftype=\"class\">str</pending_xref><desc_sig_punctuation classes=\"p\">]</desc_sig_punctuation></desc_sig_name><desc_sig_space classes=\"w\"> </desc_sig_space><desc_sig_operator classes=\"o\">=</desc_sig_operator><desc_sig_space classes=\"w\"> </desc_sig_space><inline classes=\"default_value\" support_smartquotes=\"False\">None</inline></desc_parameter></desc_parameterlist></desc_signature>\n",
      "\n",
      "Examples for <class 'docutils.nodes.system_message'>:\n",
      "<system_message backrefs=\"id2\" ids=\"id1\" level=\"3\" line=\"1\" source=\"/Users/sasha/github/LlamaIndex/llama_index/llama_index/vector_stores/postgres.py:docstring of llama_index.vector_stores.postgres.PGVectorStore\" type=\"ERROR\"><paragraph>Unknown interpreted text role ‚Äúparamref‚Äù.</paragraph></system_message>\n",
      "\n",
      "Examples for <class 'docutils.nodes.problematic'>:\n",
      "<problematic ids=\"id2\" refid=\"id1\">:paramref:`_sql.Select.with_only_columns.maintain_column_froms`</problematic>\n"
     ]
    }
   ],
   "source": [
    "# sphinx.addnodes.document\n",
    "# links are: docutils.nodes.target, section is docutils.nodes.section \n",
    "# ids is linked content, target and sections\n",
    "\n",
    "# Print all the children types of all the doctrees ids, and store in a dict\n",
    "import glob\n",
    "\n",
    "unique_types = set()\n",
    "doctree_files = glob.glob('/Users/sasha/github/LlamaIndex/llama_index/docs/_build/doctrees/**/*.doctree', recursive=True)\n",
    "doctree_files += glob.glob('/Users/sasha/github/LlamaIndex/llama_index/docs/_build/doctrees/*.doctree')\n",
    "\n",
    "type_examples = {}\n",
    "\n",
    "for file_path in doctree_files:\n",
    "    doctree = read_doctree(file_path)\n",
    "    for id in doctree.ids:\n",
    "        type_id = type(doctree.ids[id])\n",
    "        unique_types.add(type_id)\n",
    "        if type_id not in type_examples:\n",
    "            type_examples[type_id] = []\n",
    "        type_examples[type_id].append(doctree.ids[id])\n",
    "\n",
    "print(unique_types)\n",
    "for type_id, examples in type_examples.items():\n",
    "    print(f\"\\nExamples for {type_id}:\")\n",
    "    for example in examples:\n",
    "        print(example)\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discovered: these are different types of values for ids:\n",
    "- docutils.nodes.section,\n",
    "- docutils.nodes.target,\n",
    "- sphinx.addnodes.desc_signature,\n",
    "- docutils.nodes.system_message,\n",
    "- docutils.nodes.problematic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure\n",
      "{'rawsource': '', 'children': [<title: <#text: 'Welcome to Lla ...'>>, <paragraph: <#text: 'LlamaIndex is  ...'><reference...><target \"llm\" ...>, <section \"üöÄ why llamaindex?\": <title...><paragraph...><paragraph...><paragraph...><bul ...>, <section \"ü¶ô how can llamaindex help?\": <title...><paragraph...><bullet_list...>>, <section \"üë®‚Äçüë©‚Äçüëß‚Äçüë¶ who is llamaindex for?\": <title...><paragraph...><paragraph...><paragraph...>>, <section \"getting started\": <title...><paragraph...><paragraph...><paragraph...>>, <section \"üó∫Ô∏è ecosystem\": <title...><paragraph...><bullet_list...><section \"commun ...>], 'attributes': {'ids': ['welcome-to-llamaindex'], 'classes': [], 'names': ['welcome to llamaindex ü¶ô !'], 'dupnames': [], 'backrefs': []}, 'tagname': 'section', 'parent': <document: <section \"welcome to llamaindex ü¶ô !\"...>>, 'document': <document: <section \"welcome to llamaindex ü¶ô !\"...>>, 'source': '/Users/sasha/github/LlamaIndex/llama_index/docs/index.rst', 'line': 2}\n",
      "dict_keys(['rawsource', 'children', 'attributes', 'tagname', 'parent', 'document', 'source', 'line'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<title: <#text: 'Welcome to Lla ...'>>,\n",
       " <paragraph: <#text: 'LlamaIndex is  ...'><reference...><target \"llm\" ...>,\n",
       " <section \"üöÄ why llamaindex?\": <title...><paragraph...><paragraph...><paragraph...><bul ...>,\n",
       " <section \"ü¶ô how can llamaindex help?\": <title...><paragraph...><bullet_list...>>,\n",
       " <section \"üë®‚Äçüë©‚Äçüëß‚Äçüë¶ who is llamaindex for?\": <title...><paragraph...><paragraph...><paragraph...>>,\n",
       " <section \"getting started\": <title...><paragraph...><paragraph...><paragraph...>>,\n",
       " <section \"üó∫Ô∏è ecosystem\": <title...><paragraph...><bullet_list...><section \"commun ...>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_index = 0\n",
    "target_index = 1\n",
    "desc_index = 2\n",
    "system_message_index = 3\n",
    "problematic_index = 4\n",
    "all_sections = list(type_examples.values())[section_index]\n",
    "print(f\"Structure\")\n",
    "print(all_sections[0].__dict__)\n",
    "print(all_sections[0].__dict__.keys())\n",
    "all_sections[0].children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_children_type = collections.defaultdict(list)\n",
    "for section in all_sections:\n",
    "    for children in section.children:\n",
    "        section_children_type[type(children)].append(children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([<class 'docutils.nodes.title'>, <class 'docutils.nodes.paragraph'>, <class 'docutils.nodes.section'>, <class 'docutils.nodes.bullet_list'>, <class 'docutils.nodes.enumerated_list'>, <class 'docutils.nodes.compound'>, <class 'docutils.nodes.transition'>, <class 'docutils.nodes.reference'>, <class 'docutils.nodes.comment'>, <class 'docutils.nodes.block_quote'>, <class 'docutils.nodes.literal_block'>, <class 'docutils.nodes.tip'>, <class 'docutils.nodes.target'>, <class 'docutils.nodes.container'>, <class 'sphinx.addnodes.index'>, <class 'sphinx.addnodes.desc'>, <class 'sphinx.addnodes.tabular_col_spec'>, <class 'sphinx.ext.autosummary.autosummary_table'>, <class 'sphinx.ext.autosummary.autosummary_toc'>, <class 'docutils.nodes.line_block'>, <class 'docutils.nodes.raw'>, <class 'docutils.nodes.table'>, <class 'docutils.nodes.warning'>, <class 'docutils.nodes.admonition'>])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_children_type.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: <class 'docutils.nodes.title'>\n",
      "First Value Dict: {'rawsource': 'Welcome to LlamaIndex ü¶ô !', 'children': [<#text: 'Welcome to LlamaIndex ü¶ô !'>], 'attributes': {'ids': [], 'classes': [], 'names': [], 'dupnames': [], 'backrefs': []}, 'tagname': 'title', 'parent': <section \"welcome to llamaindex ü¶ô !\": <title...><paragraph...><section \"üöÄ why llamaindex?\"...> ...>, 'document': <document: <section \"welcome to llamaindex ü¶ô !\"...>>, 'source': '/Users/sasha/github/LlamaIndex/llama_index/docs/index.rst', 'line': 2}\n"
     ]
    }
   ],
   "source": [
    "for key, values in section_children_type.items():\n",
    "    print(f\"Key: {key}\")\n",
    "    print(f\"First Value Dict: {values[0].__dict__}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: Inspecting the section is interesting, but I think what benefit me more now is to look at the structure of 1 document hollistically, which I will experiment in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Holistically look at the doctree for index.doctree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title: <#text: 'Community'>>,\n",
       " <paragraph: <#text: 'Need help? Hav ...'>>,\n",
       " <bullet_list: <list_item...><list_item...>>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctree.ids[\"ecosystem\"].children[3].children\n",
    "\n",
    "# ecosystem is a section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: this informs me that I can build a parser that auto populates the content for each documents to store/index "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Langchain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnstructuredMarkdownLoader\n\u001b[1;32m      3\u001b[0m markdown_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/sasha/github/LlamaIndex/llama_index/docs/index.rst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m loader \u001b[38;5;241m=\u001b[39m UnstructuredMarkdownLoader(markdown_path)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "markdown_path = \"/Users/sasha/github/LlamaIndex/llama_index/docs/index.rst\"\n",
    "loader = UnstructuredMarkdownLoader(markdown_path)\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Welcome to LlamaIndex ü¶ô !\\n\\nLlamaIndex is a data framework for LLM <https://en.wikipedia.org/wiki/Large_language_model>-based applications to ingest, structure, and access private or domain-specific data. It\\'s available in Python (these docs) and Typescript <https://ts.llamaindex.ai/>.\\n\\nüöÄ Why LlamaIndex?\\n\\nLLMs offer a natural language interface between humans and data. Widely available models come pre-trained on huge amounts of publicly available data like Wikipedia, mailing lists, textbooks, source code and more.\\n\\nHowever, while LLMs are trained on a great deal of data, they are not trained on your data, which may be private or specific to the problem you\\'re trying to solve. It\\'s behind APIs, in SQL databases, or trapped in PDFs and slide decks.\\n\\nYou may choose to fine-tune a LLM with your data, but:\\n\\nTraining a LLM is expensive.\\n\\nDue to the cost to train, it\\'s hard to update a LLM with latest information.\\n\\nObservability is lacking. When you ask a LLM a question, it\\'s not obvious how the LLM arrived at its answer.\\n\\nLlamaIndex takes a different approach called Retrieval-Augmented Generation (RAG) <./getting_started/concepts.html>_. Instead of asking LLM to generate an answer immediately, LlamaIndex:\\n\\nretrieves information from your data sources first,\\n\\nadds it to your question as context, and\\n\\nasks the LLM to answer based on the enriched prompt.\\n\\nRAG overcomes all three weaknesses of the fine-tuning approach:\\n\\nThere\\'s no training involved, so it\\'s cheap.\\n\\nData is fetched only when you ask for them, so it\\'s always up to date.\\n\\nLlamaIndex can show you the retrieved documents, so it\\'s more trustworthy.\\n\\nLlamaIndex imposes no restriction on how you use LLMs. You can still use LLMs as auto-complete, chatbots, semi-autonomous agents, and more (see Use Cases on the left). It only makes LLMs more relevant to you.\\n\\nü¶ô How can LlamaIndex help?\\n\\nLlamaIndex provides the following tools:\\n\\nData connectors ingest your existing data from their native source and format. These could be APIs, PDFs, SQL, and (much) more.\\n\\nData indexes structure your data in intermediate representations that are easy and performant for LLMs to consume.\\n\\nEngines provide natural language access to your data. For example:\\n\\nQuery engines are powerful retrieval interfaces for knowledge-augmented output.\\n\\nChat engines are conversational interfaces for multi-message, \"back and forth\" interactions with your data.\\n\\nData agents are LLM-powered knowledge workers augmented by tools, from simple helper functions to API integrations and more.\\n\\nApplication integrations tie LlamaIndex back into the rest of your ecosystem. This could be LangChain, Flask, Docker, ChatGPT, or‚Ä¶ anything else!\\n\\nüë®\\u200düë©\\u200düëß\\u200düë¶ Who is LlamaIndex for?\\n\\nLlamaIndex provides tools for beginners, advanced users, and everyone in between.\\n\\nOur high-level API allows beginner users to use LlamaIndex to ingest and query their data in 5 lines of code.\\n\\nFor more complex applications, our lower-level APIs allow advanced users to customize and extend any module‚Äîdata connectors, indices, retrievers, query engines, reranking modules‚Äîto fit their needs.\\n\\nGetting Started\\n\\nTo install the library:\\n\\npip install llama-index\\n\\nWe recommend starting at how to read these docs <./getting_started/reading.html>_, which will point you to the right place based on your experience level.\\n\\nüó∫Ô∏è Ecosystem\\n\\nTo download or contribute, find LlamaIndex on:\\n\\nGithub: https://github.com/jerryjliu/llama_index\\n\\nPyPi:\\n\\nLlamaIndex: https://pypi.org/project/llama-index/.\\n\\nGPT Index (duplicate): https://pypi.org/project/gpt-index/.\\n\\nNPM (Typescript/Javascript):\\n\\nGithub: https://github.com/run-llama/LlamaIndexTS\\n\\nDocs: https://ts.llamaindex.ai/\\n\\nLlamaIndex.TS: https://www.npmjs.com/package/llamaindex\\n\\nCommunity\\n\\nNeed help? Have a feature suggestion? Join the LlamaIndex community:\\n\\nTwitter: https://twitter.com/llama_index\\n\\nDiscord https://discord.gg/dGcwcsnxhU\\n\\nAssociated projects\\n\\nüè° LlamaHub: https://llamahub.ai | A large (and growing!) collection of custom data connectors\\n\\nüß™ LlamaLab: https://github.com/run-llama/llama-lab | Ambitious projects built on top of LlamaIndex\\n\\n.. toctree::\\n   :maxdepth: 1\\n   :caption: Getting Started\\n   :hidden:\\n\\ngetting_started/installation.md\\n   getting_started/reading.md\\n   getting_started/starter_example.md\\n   getting_started/concepts.md\\n   getting_started/customization.rst\\n   getting_started/discover_llamaindex.md\\n\\n.. toctree::\\n   :maxdepth: 2\\n   :caption: Use Cases\\n   :hidden:\\n\\nuse_cases/q_and_a.md\\n   use_cases/chatbots.md\\n   use_cases/agents.md\\n   use_cases/extraction.md\\n   use_cases/multimodal.md\\n\\n.. toctree::\\n   :maxdepth: 2\\n   :caption: Understanding\\n   :hidden:\\n\\nunderstanding/understanding.md\\n   understanding/using_llms/using_llms.md\\n   understanding/loading/loading.md\\n   understanding/indexing/indexing.md\\n   understanding/storing/storing.md\\n   understanding/querying/querying.md\\n   understanding/putting_it_all_together/putting_it_all_together.md\\n   understanding/tracing_and_debugging/tracing_and_debugging.md\\n   understanding/evaluating/evaluating.md\\n\\n.. toctree::\\n   :maxdepth: 2\\n   :caption: Optimizing\\n   :hidden:\\n\\noptimizing/basic_strategies/basic_strategies.md\\n   optimizing/advanced_retrieval/advanced_retrieval.md\\n   optimizing/agentic_strategies/agentic_strategies.md\\n   optimizing/evaluation/evaluation.md\\n   optimizing/fine-tuning/fine-tuning.md\\n   optimizing/production_rag.md\\n   optimizing/building_rag_from_scratch.md\\n.. toctree::\\n   :maxdepth: 2\\n   :caption: Module Guides\\n   :hidden:\\n\\nmodule_guides/models/models.md\\n   module_guides/models/prompts.md\\n   module_guides/loading/loading.md\\n   module_guides/indexing/indexing.md\\n   module_guides/storing/storing.md\\n   module_guides/querying/querying.md\\n   module_guides/observability/observability.md\\n   module_guides/evaluating/root.md\\n   module_guides/supporting_modules/supporting_modules.md\\n\\n.. toctree::\\n   :maxdepth: 1\\n   :caption: API Reference\\n   :hidden:\\n\\napi_reference/index.rst\\n\\n.. toctree::\\n   :maxdepth: 2\\n   :caption: Community\\n   :hidden:\\n\\ncommunity/integrations.md\\n   community/frequently_asked_questions.md\\n   community/full_stack_projects.md\\n\\n.. toctree::\\n   :maxdepth: 2\\n   :caption: Contributing\\n   :hidden:\\n\\ncontributing/contributing.rst\\n   contributing/documentation.rst\\n\\n.. toctree::\\n   :maxdepth: 2\\n   :caption: Changes\\n   :hidden:\\n\\nchanges/changelog.rst\\n   changes/deprecated_terms.md'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].__dict__[\"page_content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this does okay, but it did not capture the fact that \"use_cases/agents.md\" etc are links "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Unstructured (with md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe index.rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.NarrativeText at 0x1bc36e190>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1bc3dc810>,\n",
       " <unstructured.documents.elements.Title at 0x1b82da3d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1b857ce90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x179965d90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1bba39f50>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bba3abd0>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bb9828d0>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bb981350>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1bb9822d0>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bb982650>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bb982910>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bb982290>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1bb982d50>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bb981050>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bb982750>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bb9812d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1bb982c10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1bb9836d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1bb980b50>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bb981110>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bb981d50>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bb981fd0>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bb983450>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bb9831d0>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bb982fd0>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bb983050>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1bb982e90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1bb982ad0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1bb9838d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1bb983510>,\n",
       " <unstructured.documents.elements.Title at 0x1bb980090>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1bb981ad0>,\n",
       " <unstructured.documents.elements.Title at 0x1bb9813d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1bb981910>,\n",
       " <unstructured.documents.elements.Title at 0x1b84fae50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x177803950>,\n",
       " <unstructured.documents.elements.ListItem at 0x1b85dded0>,\n",
       " <unstructured.documents.elements.ListItem at 0x1b868ed50>,\n",
       " <unstructured.documents.elements.ListItem at 0x179a41bd0>,\n",
       " <unstructured.documents.elements.ListItem at 0x179cc2750>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bc340690>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bc3406d0>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bc3404d0>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bc340550>,\n",
       " <unstructured.documents.elements.Title at 0x1bc340350>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1bc340190>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bc3402d0>,\n",
       " <unstructured.documents.elements.ListItem at 0x1b85bcf50>,\n",
       " <unstructured.documents.elements.Title at 0x1bbdaac90>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bb97f250>,\n",
       " <unstructured.documents.elements.ListItem at 0x1bb97fbd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1bb97fcd0>,\n",
       " <unstructured.documents.elements.Text at 0x1bb97ff90>,\n",
       " <unstructured.documents.elements.Text at 0x1bb97fd90>,\n",
       " <unstructured.documents.elements.Text at 0x1bb97f0d0>,\n",
       " <unstructured.documents.elements.Text at 0x1bb97f3d0>,\n",
       " <unstructured.documents.elements.Text at 0x1bb97f8d0>,\n",
       " <unstructured.documents.elements.Text at 0x1bb97eed0>,\n",
       " <unstructured.documents.elements.Text at 0x1bb97efd0>,\n",
       " <unstructured.documents.elements.Text at 0x1bb97ef50>,\n",
       " <unstructured.documents.elements.Text at 0x1bb97f4d0>,\n",
       " <unstructured.documents.elements.Title at 0x1bb97f610>,\n",
       " <unstructured.documents.elements.Text at 0x1b856eb10>,\n",
       " <unstructured.documents.elements.Title at 0x1b8666210>,\n",
       " <unstructured.documents.elements.Text at 0x1bc3dca10>,\n",
       " <unstructured.documents.elements.Title at 0x1bc3dca90>,\n",
       " <unstructured.documents.elements.Text at 0x1bc3dcc10>,\n",
       " <unstructured.documents.elements.Title at 0x1bc3dcd50>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unstructured.partition.md import partition_md\n",
    "elements = partition_md(filename=\"/Users/sasha/github/LlamaIndex/llama_index/docs/index.rst\")\n",
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'.. toctree::\\n   :maxdepth: 1\\n   :caption: Getting Started\\n   :hidden:'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(elements))\n",
    "elements[52].text # everything after 52 for index.rst is structure, observe another random file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe another random md file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.Title at 0x162565f10>,\n",
       " <unstructured.documents.elements.Title at 0x16255c7d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258c710>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x162566d10>,\n",
       " <unstructured.documents.elements.Title at 0x16258cc90>,\n",
       " <unstructured.documents.elements.Title at 0x16258cf10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258d010>,\n",
       " <unstructured.documents.elements.Title at 0x16258d110>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258d210>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258d2d0>,\n",
       " <unstructured.documents.elements.Title at 0x16258d390>,\n",
       " <unstructured.documents.elements.Title at 0x16258d490>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258d590>,\n",
       " <unstructured.documents.elements.Title at 0x16258d690>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258d790>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258d890>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258d990>,\n",
       " <unstructured.documents.elements.ListItem at 0x16258dad0>,\n",
       " <unstructured.documents.elements.Text at 0x16258dc10>,\n",
       " <unstructured.documents.elements.ListItem at 0x16258dc90>,\n",
       " <unstructured.documents.elements.Title at 0x16258ddd0>,\n",
       " <unstructured.documents.elements.ListItem at 0x16258ded0>,\n",
       " <unstructured.documents.elements.Title at 0x16258dfd0>,\n",
       " <unstructured.documents.elements.Title at 0x16258e0d0>,\n",
       " <unstructured.documents.elements.Title at 0x16258e1d0>,\n",
       " <unstructured.documents.elements.Title at 0x16258e2d0>,\n",
       " <unstructured.documents.elements.Title at 0x16258e3d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258e4d0>,\n",
       " <unstructured.documents.elements.Title at 0x16258e5d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258e6d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258e7d0>,\n",
       " <unstructured.documents.elements.Title at 0x16258e8d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258e9d0>,\n",
       " <unstructured.documents.elements.Title at 0x16258ead0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258ebd0>,\n",
       " <unstructured.documents.elements.Title at 0x16258ecd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258edd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258eed0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258efd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258f0d0>,\n",
       " <unstructured.documents.elements.Title at 0x16258f1d0>,\n",
       " <unstructured.documents.elements.Title at 0x16258f2d0>,\n",
       " <unstructured.documents.elements.Title at 0x16258f3d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258f4d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258f5d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258f6d0>,\n",
       " <unstructured.documents.elements.Title at 0x16258f7d0>,\n",
       " <unstructured.documents.elements.Title at 0x16258f8d0>,\n",
       " <unstructured.documents.elements.Title at 0x16258f9d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258fb10>,\n",
       " <unstructured.documents.elements.ListItem at 0x16258fc10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258fd10>,\n",
       " <unstructured.documents.elements.ListItem at 0x16258fe10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x16258ff10>,\n",
       " <unstructured.documents.elements.ListItem at 0x1625a0090>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1625a0190>,\n",
       " <unstructured.documents.elements.Title at 0x1625a0290>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1625a0390>,\n",
       " <unstructured.documents.elements.Title at 0x1625a0490>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1625a0590>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1625a0690>,\n",
       " <unstructured.documents.elements.Title at 0x1625a0790>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1625a0890>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1625a0990>,\n",
       " <unstructured.documents.elements.Title at 0x1625a0a90>,\n",
       " <unstructured.documents.elements.Title at 0x1625a0b90>,\n",
       " <unstructured.documents.elements.Title at 0x1625a0c90>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unstructured.partition.md import partition_md\n",
    "elements = partition_md(filename=\"/Users/sasha/github/LlamaIndex/llama_index/docs/module_guides/loading/documents_and_nodes/usage_documents.md\")\n",
    "elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "<class 'unstructured.documents.elements.Text'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'python\\ndocument = Document(\\n    text=\"text\",\\n    metadata={\"filename\": \"<doc_file_name>\", \"category\": \"<category>\"},\\n)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(elements))\n",
    "index = 18 # 61\n",
    "print(type(elements[index]))\n",
    "elements[index].text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inspecting links (this maybe a deal breaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'unstructured.documents.elements.NarrativeText'>\n",
      "By default, all of our data loaders (including those offered on LlamaHub) return Document objects through the load_data function.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'last_modified': '2024-01-08T15:19:23',\n",
       " '_known_field_names': frozenset({'attached_to_filename',\n",
       "            'category_depth',\n",
       "            'coordinates',\n",
       "            'data_source',\n",
       "            'detection_class_prob',\n",
       "            'detection_origin',\n",
       "            'emphasized_text_contents',\n",
       "            'emphasized_text_tags',\n",
       "            'file_directory',\n",
       "            'filename',\n",
       "            'filetype',\n",
       "            'header_footer_type',\n",
       "            'image_base64',\n",
       "            'image_mime_type',\n",
       "            'image_path',\n",
       "            'is_continuation',\n",
       "            'languages',\n",
       "            'last_modified',\n",
       "            'link_texts',\n",
       "            'link_urls',\n",
       "            'links',\n",
       "            'page_name',\n",
       "            'page_number',\n",
       "            'parent_id',\n",
       "            'regex_metadata',\n",
       "            'section',\n",
       "            'sent_from',\n",
       "            'sent_to',\n",
       "            'subject',\n",
       "            'text_as_html',\n",
       "            'url'}),\n",
       " 'page_number': 1,\n",
       " 'languages': ['eng'],\n",
       " 'parent_id': '6edae678f82d241a17e6eb7bb78f3b86',\n",
       " 'filetype': 'text/markdown',\n",
       " 'file_directory': '/Users/sasha/github/LlamaIndex/llama_index/docs/module_guides/loading/documents_and_nodes',\n",
       " 'filename': 'usage_documents.md'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 3\n",
    "print(type(elements[index]))\n",
    "print(elements[index].text) # note this is supposed to have a link under \"dataloader\"\n",
    "elements[index].metadata.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: its not super clear the difference between narrativeText with Text, and also links are not captured in markdown with unstructured... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding how the sidebar structure is determined, in the root.md file, pay attention to toctree structure's includefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<document: <section \"querying\"...>>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace 'path_to_doctree_file.doctree' with your .doctree file path\n",
    "# doctree = read_doctree('/Users/sasha/github/LlamaIndex/llama_index/docs/_build/doctrees/index.doctree')\n",
    "# agentic_strategies_doctree = read_doctree('/Users/sasha/github/LlamaIndex/llama_index/docs/_build/doctrees/optimizing/advanced_retrieval/advanced_retrieval.doctree')\n",
    "querying_doctree = read_doctree('/Users/sasha/github/LlamaIndex/llama_index/docs/_build/doctrees/module_guides/querying/querying.doctree')\n",
    "# print(doctree)\n",
    "# print(agentic_strategies_doctree)\n",
    "querying_doctree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rawsource': '',\n",
       " 'children': [],\n",
       " 'attributes': {'ids': [],\n",
       "  'classes': [],\n",
       "  'names': [],\n",
       "  'dupnames': [],\n",
       "  'backrefs': [],\n",
       "  'parent': 'module_guides/querying/querying',\n",
       "  'entries': [(None, 'module_guides/deploying/query_engine/root'),\n",
       "   (None, 'module_guides/deploying/chat_engines/root'),\n",
       "   (None, 'module_guides/deploying/agents/root'),\n",
       "   (None, 'module_guides/querying/retriever/root'),\n",
       "   (None, 'module_guides/querying/response_synthesizers/root'),\n",
       "   (None, 'module_guides/querying/router/root'),\n",
       "   (None, 'module_guides/querying/node_postprocessors/root'),\n",
       "   (None, 'module_guides/querying/structured_outputs/structured_outputs')],\n",
       "  'includefiles': ['module_guides/deploying/query_engine/root',\n",
       "   'module_guides/deploying/chat_engines/root',\n",
       "   'module_guides/deploying/agents/root',\n",
       "   'module_guides/querying/retriever/root',\n",
       "   'module_guides/querying/response_synthesizers/root',\n",
       "   'module_guides/querying/router/root',\n",
       "   'module_guides/querying/node_postprocessors/root',\n",
       "   'module_guides/querying/structured_outputs/structured_outputs'],\n",
       "  'maxdepth': 1,\n",
       "  'caption': None,\n",
       "  'glob': False,\n",
       "  'hidden': False,\n",
       "  'includehidden': False,\n",
       "  'numbered': 0,\n",
       "  'titlesonly': False,\n",
       "  'rawentries': []},\n",
       " 'tagname': 'toctree',\n",
       " 'source': '/Users/sasha/github/LlamaIndex/llama_index/docs/module_guides/querying/querying.md',\n",
       " 'line': 21,\n",
       " 'parent': <compound: <toctree...>>}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "querying_doctree.ids[\"query-modules\"].children[1].children[0].__dict__\n",
    "# interesting that <compound: <toctree...>>\n",
    "# in a given section basically denotes the sidebar content, this is the structure of toctree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if ipynb is included in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<document: <section \"agents\"...>>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_doctree = read_doctree('/Users/sasha/github/LlamaIndex/llama_index/docs/_build/doctrees/use_cases/agents.doctree')\n",
    "agent_doctree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rawsource': '',\n",
       " 'children': [],\n",
       " 'attributes': {'ids': [],\n",
       "  'classes': [],\n",
       "  'names': [],\n",
       "  'dupnames': [],\n",
       "  'backrefs': [],\n",
       "  'parent': 'use_cases/agents',\n",
       "  'entries': [('Agents (Putting your RAG Pipeline Together)',\n",
       "    'understanding/putting_it_all_together/agents'),\n",
       "   ('Agentic Strategies (Optimizing your RAG Pipeline)',\n",
       "    'optimizing/agentic_strategies/agentic_strategies')],\n",
       "  'includefiles': ['understanding/putting_it_all_together/agents',\n",
       "   'optimizing/agentic_strategies/agentic_strategies'],\n",
       "  'maxdepth': 1,\n",
       "  'caption': None,\n",
       "  'glob': False,\n",
       "  'hidden': False,\n",
       "  'includehidden': False,\n",
       "  'numbered': 0,\n",
       "  'titlesonly': False,\n",
       "  'rawentries': ['Agents (Putting your RAG Pipeline Together)',\n",
       "   'Agentic Strategies (Optimizing your RAG Pipeline)']},\n",
       " 'tagname': 'toctree',\n",
       " 'source': '/Users/sasha/github/LlamaIndex/llama_index/docs/use_cases/agents.md',\n",
       " 'line': 24,\n",
       " 'parent': <compound: <toctree...>>}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_doctree.children[0].children[5].children[2].children[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<document: <paragraph...><section \"context-augmented openai agent\"...>>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook_tree = read_doctree('/Users/sasha/github/LlamaIndex/llama_index/docs/_build/doctrees/examples/agent/openai_agent_context_retrieval.doctree')\n",
    "notebook_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rawsource': '!pip install llama-index',\n",
       " 'children': [<#text: '!pip install llama-index'>],\n",
       " 'attributes': {'ids': [],\n",
       "  'classes': [],\n",
       "  'names': [],\n",
       "  'dupnames': [],\n",
       "  'backrefs': [],\n",
       "  'language': 'ipython3',\n",
       "  'xml:space': 'preserve'},\n",
       " 'tagname': 'literal_block',\n",
       " 'source': '/Users/sasha/github/LlamaIndex/llama_index/docs/examples/agent/openai_agent_context_retrieval.ipynb',\n",
       " 'line': 70002,\n",
       " 'parent': <container: <literal_block...>>,\n",
       " 'document': <document: <paragraph...><section \"context-augmented openai agent\"...>>}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook_tree.children[1].children[2][3].children[0].children[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<paragraph: <raw...><raw...><raw...>>,\n",
       " <section \"context-augmented openai agent\": <title...><paragraph...><section \"initial setup\"...>>]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook_tree.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title: <#text: 'Context-Augmen ...'>>,\n",
       " <paragraph: <#text: 'In this tutori ...'><literal...><#text: ' imple ...>,\n",
       " <section \"initial setup\": <title...><paragraph...><paragraph...><container...><con ...>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook_tree.children[1].children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rawsource': '',\n",
       " 'children': [<title: <#text: 'Initial Setup'>>,\n",
       "  <paragraph: <#text: 'Here we setup  ...'>>,\n",
       "  <paragraph: <#text: 'If you‚Äôre open ...'>>,\n",
       "  <container: <container...>>,\n",
       "  <container: <container...>>,\n",
       "  <container: <container...>>,\n",
       "  <paragraph: <#text: 'Download Data'>>,\n",
       "  <container: <container...>>,\n",
       "  <container: <container...>>,\n",
       "  <container: <container...>>,\n",
       "  <container: <container...>>,\n",
       "  <section \"try context-augmented agent\": <title...><paragraph...><bullet_list...><container...><c ...>,\n",
       "  <section \"use uber 10-q as context, use calculator as tool\": <title...><container...><container...><container...><con ...>],\n",
       " 'attributes': {'ids': ['initial-setup'],\n",
       "  'classes': [],\n",
       "  'names': ['initial setup'],\n",
       "  'dupnames': [],\n",
       "  'backrefs': [],\n",
       "  'myst-anchor': 'examples/agent/openai_agent_context_retrieval.ipynb#initial-setup'},\n",
       " 'tagname': 'section',\n",
       " 'line': 40002,\n",
       " 'source': '/Users/sasha/github/LlamaIndex/llama_index/docs/examples/agent/openai_agent_context_retrieval.ipynb',\n",
       " 'parent': <section \"context-augmented openai agent\": <title...><paragraph...><section \"initial setup\"...>>,\n",
       " 'document': <document: <paragraph...><section \"context-augmented openai agent\"...>>}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook_tree.children[1].children[2].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rawsource': '',\n",
       " 'children': [<container: <literal_block...>>],\n",
       " 'attributes': {'ids': [],\n",
       "  'classes': ['cell'],\n",
       "  'names': [],\n",
       "  'dupnames': [],\n",
       "  'backrefs': [],\n",
       "  'nb_element': 'cell_code',\n",
       "  'cell_index': 6,\n",
       "  'exec_count': None,\n",
       "  'cell_metadata': {}},\n",
       " 'tagname': 'container',\n",
       " 'line': 70002,\n",
       " 'source': '/Users/sasha/github/LlamaIndex/llama_index/docs/examples/agent/openai_agent_context_retrieval.ipynb',\n",
       " 'parent': <section \"initial setup\": <title...><paragraph...><paragraph...><container...><con ...>,\n",
       " 'document': <document: <paragraph...><section \"context-augmented openai agent\"...>>}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each container block is code and within each container block, it has additional container\n",
    "notebook_tree.children[1].children[2][3].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rawsource': '', 'parent': <literal_block: <#text: '!pip install l ...'>>}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook_tree.children[1].children[2][3].children[0].children[0].children[0].__dict__ # , it has an additional container which leads to a literal block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion is that I should use sphinx as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Unstructured (with HTML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.auto import partition\n",
    "from unstructured.staging.base import elements_to_json\n",
    "\n",
    "# input_filename = \"/Users/sasha/github/LlamaIndex/llama_index/docs/_build/html/api_reference/multi_modal/openai.html\"\n",
    "input_filename = \"/Users/sasha/github/LlamaIndex/llama_index/docs/_build/html/getting_started/installation.html\"\n",
    "# output_filename=\"api_ref_multimodal_openai.json\"\n",
    "output_filename = \"getting_started_installation.json\"\n",
    "elements = partition(filename=input_filename)\n",
    "elements_to_json(elements, filename=output_filename) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^ oh interesting. This actually works.\n",
    "output_filepath=\"/Users/sasha/github/LlamaIndex/Experiments/index.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.md import partition_md\n",
    "from unstructured.staging.base import elements_to_json\n",
    "\n",
    "# input_filename = \"/Users/sasha/github/LlamaIndex/llama_index/docs/index.rst\"\n",
    "input_filename = \"/Users/sasha/github/LlamaIndex/llama_index/docs/module_guides/loading/documents_and_nodes/usage_documents.md\"\n",
    "output_filename=\"usage_documents_from_md.json\"\n",
    "elements = partition_md(filename=input_filename)\n",
    "elements_to_json(elements, filename=output_filename) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using unstructured HTML, generate index.txt as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hide navigation sidebar(Title)\n",
      "Hide table of contents sidebar(Title)\n",
      "Toggle site navigation sidebar(Title)\n",
      "LlamaIndex ü¶ô 0.9.31(NarrativeText)\n",
      "Toggle Light / Dark / Auto color theme(Title)\n",
      "Toggle table of contents sidebar(Title)\n",
      "LlamaIndex ü¶ô 0.9.31(NarrativeText)\n",
      "Getting Started(Title)\n",
      "Installation and Setup(ListItem)\n",
      "How to read these docs(ListItem)\n",
      "Starter Tutorial(ListItem)\n",
      "High-Level Concepts(ListItem)\n",
      "Customization Tutorial(ListItem)\n",
      "Discover LlamaIndex Video Series(ListItem)\n",
      "Use Cases(Title)\n",
      "Q&A(ListItem)\n",
      "Chatbots(ListItem)\n",
      "AgentsToggle child pages in navigation\n",
      "Agents (Putting your RAG Pipeline Together)Toggle child pages in navigation\n",
      "Build your own OpenAI Agent\n",
      "OpenAI Agent with Query Engine Tools\n",
      "OpenAI Agent Query Planning\n",
      "OpenAI Assistant Agent\n",
      "OpenAI Assistant Advanced Retrieval Cookbook\n",
      "OpenAI agent: specifying a forced function call\n",
      "Single-Turn Multi-Function Calling OpenAI Agents\n",
      "Context-Augmented OpenAI Agent\n",
      "\n",
      "\n",
      "Agentic Strategies (Optimizing your RAG Pipeline)Toggle child pages in navigation\n",
      "RoutersToggle child pages in navigation\n",
      "Router Query Engine\n",
      "Retriever Router Query Engine\n",
      "SQL Router Query Engine\n",
      "Router Retriever\n",
      "\n",
      "\n",
      "Query TransformationsToggle child pages in navigation\n",
      "HyDE Query Transform\n",
      "Multi-Step Query Engine\n",
      "\n",
      "\n",
      "Sub Question Query Engine (Intro)\n",
      "Build your own OpenAI Agent\n",
      "OpenAI Agent with Query Engine Tools\n",
      "Retrieval-Augmented OpenAI Agent\n",
      "OpenAI Agent + Query Engine Experimental Cookbook\n",
      "OpenAI Agent Query Planning\n",
      "Context-Augmented OpenAI Agent\n",
      "\n",
      "\n",
      "Data AgentsToggle child pages in navigation\n",
      "Usage Pattern\n",
      "Module GuidesToggle child pages in navigation\n",
      "Build your own OpenAI Agent\n",
      "OpenAI Agent with Query Engine Tools\n",
      "Retrieval-Augmented OpenAI Agent\n",
      "OpenAI Agent + Query Engine Experimental Cookbook\n",
      "OpenAI Agent Query Planning\n",
      "Context-Augmented OpenAI Agent\n",
      "Recursive Retriever + Document Agents\n",
      "Multi-Document Agents\n",
      "GPT Builder Demo\n",
      "Single-Turn Multi-Function Calling OpenAI Agents\n",
      "OpenAI Assistant Agent\n",
      "Benchmarking OpenAI Retrieval API (through Assistant Agent)\n",
      "OpenAI Assistant Advanced Retrieval Cookbook\n",
      "ReAct Agent with Query Engine Tools\n",
      "LLMCompiler Agent Cookbook\n",
      "Building a Custom Agent\n",
      "Step-wise, Controllable Agents\n",
      "Controllable Agents for RAG\n",
      "Controllable Agents for RAG\n",
      "\n",
      "\n",
      "ToolsToggle child pages in navigation\n",
      "Usage Pattern\n",
      "LlamaHub Tools Guide\n",
      "\n",
      "\n",
      "Lower-Level Agent API\n",
      "\n",
      "\n",
      "ToolsToggle child pages in navigation\n",
      "Usage Pattern\n",
      "LlamaHub Tools Guide(ListItem)\n",
      "Structured Data ExtractionToggle child pages in navigation\n",
      "Structured OutputsToggle child pages in navigation\n",
      "Pydantic ProgramToggle child pages in navigation\n",
      "LLM Pydantic Program\n",
      "OpenAI Pydantic Program\n",
      "Guidance Pydantic Program\n",
      "Guidance for Sub-Question Query Engine\n",
      "DataFrame Structured Data Extraction\n",
      "Evaporate Demo\n",
      "\n",
      "\n",
      "Query Engines + Pydantic OutputsToggle child pages in navigation\n",
      "Query Engine with Pydantic Outputs\n",
      "Pydantic Tree Summarize\n",
      "Download Data\n",
      "\n",
      "\n",
      "Output Parsing ModulesToggle child pages in navigation\n",
      "Guardrails Output Parsing\n",
      "Langchain Output Parsing\n",
      "Guidance Pydantic Program\n",
      "Guidance for Sub-Question Query Engine\n",
      "OpenAI Pydantic Program\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Output Parsing ModulesToggle child pages in navigation\n",
      "Guardrails Output Parsing\n",
      "Langchain Output Parsing\n",
      "Guidance Pydantic Program\n",
      "Guidance for Sub-Question Query Engine\n",
      "OpenAI Pydantic Program\n",
      "\n",
      "\n",
      "Extracting names and locations from descriptions of people\n",
      "Extracting album data from music reviews\n",
      "Extracting information from emails(ListItem)\n",
      "Multi-modalToggle child pages in navigation\n",
      "Advanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\n",
      "Multi-modal retrieval with CLIP\n",
      "Image to Image Retrieval\n",
      "Semi-structured Image Retrieval\n",
      "Chroma Multi-Modal Demo with LlamaIndex\n",
      "Multi-Modal on PDF‚Äôs with tables.\n",
      "Multi-Modal GPT4V Pydantic Program\n",
      "Retrieval-Augmented Image Captioning\n",
      "[Beta] Multi-modal ReAct Agent\n",
      "GPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\n",
      "Multi-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\n",
      "GPT4-V:\n",
      "Evaluating Multi-Modal RAG(ListItem)\n",
      "Understanding(Title)\n",
      "Building an LLM application(ListItem)\n",
      "Using LLMsToggle child pages in navigation\n",
      "Privacy and Security(ListItem)\n",
      "Loading Data (Ingestion)Toggle child pages in navigation\n",
      "LlamaHub\n",
      "Documents / NodesToggle child pages in navigation\n",
      "Defining and Customizing DocumentsToggle child pages in navigation\n",
      "Metadata Extraction Usage PatternToggle child pages in navigation\n",
      "Extracting Metadata for Better Document Indexing and Understanding\n",
      "Automated Metadata Extraction for Better Retrieval + Synthesis\n",
      "Entity Metadata Extraction\n",
      "Metadata Extraction and Augmentation w/ Marvin\n",
      "Pydantic Extractor\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Defining and Customizing Nodes\n",
      "Transformations\n",
      "\n",
      "\n",
      "Node Parser Usage PatternToggle child pages in navigation\n",
      "Node Parser Modules\n",
      "\n",
      "\n",
      "Ingestion PipelineToggle child pages in navigation\n",
      "Transformations\n",
      "Advanced Ingestion Pipeline\n",
      "Async Ingestion Pipeline + Metadata Extraction\n",
      "Ingestion Pipeline + Document Management\n",
      "Redis Ingestion Pipeline\n",
      "Building a Live RAG Pipeline over Google Drive Files\n",
      "Parallelizing Ingestion Pipeline(ListItem)\n",
      "Indexing(ListItem)\n",
      "Storing(ListItem)\n",
      "Querying(ListItem)\n",
      "Putting It All TogetherToggle child pages in navigation\n",
      "Q&A patternsToggle child pages in navigation\n",
      "A Guide to Extracting Terms and Definitions\n",
      "A Guide to Creating a Unified Query Framework over your Indexes\n",
      "Knowledge Graphs\n",
      "Structured Data\n",
      "A Guide to LlamaIndex + Structured Data\n",
      "Airbyte SQL Index Guide\n",
      "\n",
      "\n",
      "Full-Stack Web ApplicationToggle child pages in navigation\n",
      "A Guide to Building a Full-Stack Web App with LLamaIndex\n",
      "A Guide to Building a Full-Stack LlamaIndex Web App with Delphic\n",
      "\n",
      "\n",
      "How to Build a Chatbot\n",
      "AgentsToggle child pages in navigation\n",
      "Build your own OpenAI Agent\n",
      "OpenAI Agent with Query Engine Tools\n",
      "OpenAI Agent Query Planning\n",
      "OpenAI Assistant Agent\n",
      "OpenAI Assistant Advanced Retrieval Cookbook\n",
      "OpenAI agent: specifying a forced function call\n",
      "Single-Turn Multi-Function Calling OpenAI Agents\n",
      "Context-Augmented OpenAI Agent\n",
      "\n",
      "\n",
      "Full-Stack ProjectsToggle child pages in navigation\n",
      "create-llama Blog\n",
      "create-llama Repo\n",
      "create-llama Additional Templates\n",
      "SEC Insights App\n",
      "SEC Insights Repo\n",
      "Chat LlamaIndex App\n",
      "Chat LlamaIndex Repo\n",
      "RAGs Repo(ListItem)\n",
      "Tracing and Debugging(ListItem)\n",
      "EvaluatingToggle child pages in navigation\n",
      "Cost AnalysisToggle child pages in navigation\n",
      "Usage Pattern(ListItem)\n",
      "Optimizing(Title)\n",
      "Basic StrategiesToggle child pages in navigation\n",
      "Accessing/Customizing Prompts within Higher-Level Modules\n",
      "Advanced Prompt Techniques (Variable Mappings, Functions)\n",
      "Advanced Prompt Techniques (Variable Mappings, Functions)\n",
      "Prompt Engineering for RAG\n",
      "BM25 Retriever\n",
      "Reciprocal Rerank Fusion Retriever\n",
      "Weaviate Vector Store - Hybrid Search\n",
      "Pinecone Vector Store - Hybrid Search\n",
      "Vector Store Index usage examples\n",
      "Defining and Customizing DocumentsToggle child pages in navigation\n",
      "Metadata Extraction Usage PatternToggle child pages in navigation\n",
      "Extracting Metadata for Better Document Indexing and Understanding\n",
      "Automated Metadata Extraction for Better Retrieval + Synthesis\n",
      "Entity Metadata Extraction\n",
      "Metadata Extraction and Augmentation w/ Marvin\n",
      "Pydantic Extractor\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Defining and Customizing Nodes\n",
      "Metadata Extraction Usage PatternToggle child pages in navigation\n",
      "Extracting Metadata for Better Document Indexing and Understanding\n",
      "Automated Metadata Extraction for Better Retrieval + Synthesis\n",
      "Entity Metadata Extraction\n",
      "Metadata Extraction and Augmentation w/ Marvin\n",
      "Pydantic Extractor\n",
      "\n",
      "\n",
      "Multi-Tenancy RAG with LlamaIndex(ListItem)\n",
      "Advanced Retrieval StrategiesToggle child pages in navigation\n",
      "Query Transform Cookbook\n",
      "Query TransformationsToggle child pages in navigation\n",
      "HyDE Query Transform\n",
      "Multi-Step Query Engine\n",
      "\n",
      "\n",
      "DeepMemory (Activeloop)\n",
      "Weaviate Vector Store - Hybrid Search\n",
      "Pinecone Vector Store - Hybrid Search(ListItem)\n",
      "Agentic strategiesToggle child pages in navigation\n",
      "RoutersToggle child pages in navigation\n",
      "Router Query Engine\n",
      "Retriever Router Query Engine\n",
      "SQL Router Query Engine\n",
      "Router Retriever\n",
      "\n",
      "\n",
      "Query TransformationsToggle child pages in navigation\n",
      "HyDE Query Transform\n",
      "Multi-Step Query Engine\n",
      "\n",
      "\n",
      "Sub Question Query Engine (Intro)\n",
      "Build your own OpenAI Agent\n",
      "OpenAI Agent with Query Engine Tools\n",
      "Retrieval-Augmented OpenAI Agent\n",
      "OpenAI Agent + Query Engine Experimental Cookbook\n",
      "OpenAI Agent Query Planning\n",
      "Context-Augmented OpenAI Agent(ListItem)\n",
      "EvaluationToggle child pages in navigation\n",
      "End-to-End EvaluationToggle child pages in navigation\n",
      "QuestionGeneration\n",
      "BatchEvalRunner - Running Multiple Evaluations\n",
      "Correctness Evaluator\n",
      "Faithfulness Evaluator\n",
      "Guideline Evaluator\n",
      "Pairwise Evaluator\n",
      "Relevancy Evaluator\n",
      "Embedding Similarity Evaluator\n",
      "\n",
      "\n",
      "Component Wise EvaluationToggle child pages in navigation\n",
      "BEIR Out of Domain Benchmark\n",
      "HotpotQADistractor Demo\n",
      "\n",
      "\n",
      "EvaluatingToggle child pages in navigation\n",
      "Usage Pattern (Response Evaluation)\n",
      "Usage Pattern (Retrieval)\n",
      "ModulesToggle child pages in navigation\n",
      "Faithfulness Evaluator\n",
      "Relevancy Evaluator\n",
      "Answer Relevancy and Context Relevancy Evaluations\n",
      "Guideline Evaluator\n",
      "Correctness Evaluator\n",
      "Embedding Similarity Evaluator\n",
      "LlamaIndex + DeepEval Integration\n",
      "QuestionGeneration\n",
      "BatchEvalRunner - Running Multiple Evaluations\n",
      "Evaluating Multi-Modal RAG\n",
      "Retrieval Evaluation\n",
      "\n",
      "\n",
      "Evaluating With LabelledRagDataset‚ÄôsToggle child pages in navigation\n",
      "Benchmarking RAG Pipelines With A LabelledRagDatatset\n",
      "Downloading a LlamaDataset from LlamaHub\n",
      "\n",
      "\n",
      "Contributing A LabelledRagDatasetToggle child pages in navigation\n",
      "LlamaDataset Submission Template Notebook\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Component Wise EvaluationToggle child pages in navigation\n",
      "BEIR Out of Domain Benchmark\n",
      "HotpotQADistractor Demo\n",
      "\n",
      "\n",
      "End-to-End EvaluationToggle child pages in navigation\n",
      "QuestionGeneration\n",
      "BatchEvalRunner - Running Multiple Evaluations\n",
      "Correctness Evaluator\n",
      "Faithfulness Evaluator\n",
      "Guideline Evaluator\n",
      "Pairwise Evaluator\n",
      "Relevancy Evaluator\n",
      "Embedding Similarity Evaluator(ListItem)\n",
      "Fine-tuningToggle child pages in navigation\n",
      "Fine-tuning an Adapter\n",
      "Embedding Fine-tuning Guide\n",
      "Router Fine-tuning\n",
      "Embedding Fine-tuning Repo\n",
      "Embedding Fine-tuning Blog\n",
      "GPT-3.5 Fine-tuning Notebook (Colab)\n",
      "GPT-3.5 Fine-tuning Notebook (Notebook link)\n",
      "Fine-tuning a gpt-3.5 ReAct Agent on Better Chain of Thought\n",
      "[WIP] Function Calling Fine-tuning\n",
      "GPT-3.5 Fine-tuning Notebook (Colab)\n",
      "GPT-3.5 Fine-tuning Notebook (in Repo)\n",
      "Fine-tuning with Retrieval Augmentation\n",
      "OpenAI Function Calling Fine-tuning\n",
      "Llama2 Structured Output Fine-tuning\n",
      "Fine-tuning to Memorize Knowledge\n",
      "Llama 2 Text-to-SQL Fine-tuning (w/ Gradient.AI)\n",
      "Llama 2 Text-to-SQL Fine-tuning (w/ Modal, Repo)\n",
      "Llama 2 Text-to-SQL Fine-tuning (w/ Modal, Notebook)\n",
      "Knowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Correctness)\n",
      "Knowledge Distillation For Fine-Tuning A GPT-3.5 Judge (Pairwise)\n",
      "Cross-Encoder Finetuning\n",
      "Finetuning Llama 2 for Text-to-SQL\n",
      "Finetuning GPT-3.5 to Distill GPT-4\n",
      "Cohere Custom Reranker(ListItem)\n",
      "Building Performant RAG Applications for ProductionToggle child pages in navigation\n",
      "Recursive Retriever + Query Engine Demo\n",
      "Document Summary Index\n",
      "Metadata Replacement + Node Sentence Window\n",
      "Auto-Retrieval from a Vector Database\n",
      "Document Summary Index\n",
      "Recursive Retriever + Document Agents\n",
      "Comparing Methods for Structured Retrieval (Auto-Retrieval vs. Recursive Retrieval)\n",
      "Sub Question Query Engine\n",
      "Joint QA Summary Query Engine\n",
      "Recursive Retriever + Document Agents\n",
      "Router Query Engine\n",
      "OpenAI Agent + Query Engine Experimental Cookbook\n",
      "OpenAI Agent Query Planning\n",
      "Embedding Fine-tuning Guide(ListItem)\n",
      "Building RAG from Scratch (Lower-Level)Toggle child pages in navigation\n",
      "Building Data Ingestion from Scratch\n",
      "Pinecone\n",
      "OpenAI\n",
      "Building Retrieval from Scratch\n",
      "Building RAG from Scratch (Open-source only!)\n",
      "Building a (Very Simple) Vector Store from Scratch\n",
      "Building Response Synthesis from Scratch\n",
      "Building Evaluation from Scratch\n",
      "Building Hybrid Search from Scratch\n",
      "Building a Router from Scratch\n",
      "Building an Advanced Fusion Retriever from Scratch\n",
      "Query Pipeline for Text-to-SQL\n",
      "Query Pipeline over Pandas DataFrames(ListItem)\n",
      "Module Guides(Title)\n",
      "ModelsToggle child pages in navigation\n",
      "Using LLMsToggle child pages in navigation\n",
      "Using LLMs as standalone modules\n",
      "Customizing LLMs within LlamaIndex Abstractions\n",
      "Available LLM integrationsToggle child pages in navigation\n",
      "AI21\n",
      "Anthropic\n",
      "Anyscale\n",
      "Bedrock\n",
      "Connect to Bedrock with Access Keys\n",
      "Clarifai LLM\n",
      "EverlyAI\n",
      "Gradient Base Model\n",
      "Gradient Model Adapter\n",
      "HuggingFace LLM - Camel-5b\n",
      "HuggingFace LLM - StableLM\n",
      "Local Llama2 + VectorStoreIndex\n",
      "Konko\n",
      "LangChain LLM\n",
      "LiteLLM\n",
      "Llama API\n",
      "LlamaCPP\n",
      "LocalAI\n",
      "MistralAI\n",
      "Monster API LLM Integration into LLamaIndex\n",
      "Neutrino AI\n",
      "Nvidia TensorRT-LLM\n",
      "Nvidia Triton\n",
      "Ollama - Llama 2 7B\n",
      "OpenAI\n",
      "Azure OpenAI\n",
      "OpenLLM\n",
      "OpenRouter\n",
      "PaLM\n",
      "Perplexity\n",
      "Portkey\n",
      "Predibase\n",
      "Replicate - Llama 2 13B\n",
      "Replicate - Vicuna 13B\n",
      "Llama2 + VectorStoreIndex\n",
      "RunGPT\n",
      "Setup\n",
      "Togather AI LLM\n",
      "Getting Started\n",
      "Basic auth example for service account\n",
      "Streaming Usage\n",
      "Chat Usage\n",
      "Async Chat\n",
      "Streaming Chat\n",
      "Gemini Models\n",
      "Install Vllm\n",
      "Orca-7b Completion Example\n",
      "LLama-2-7b Completion Example\n",
      "mistral chat 7b Completion Example\n",
      "Api Response\n",
      "Xorbits Inference\n",
      "\n",
      "\n",
      "EmbeddingsToggle child pages in navigation\n",
      "Azure OpenAI\n",
      "Embeddings with Clarifai\n",
      "CohereAI Embeddings\n",
      "Custom Embeddings\n",
      "Elasticsearch Embeddings\n",
      "Qdrant FastEmbed Embeddings\n",
      "Google PaLM Embeddings\n",
      "Gradient Embeddings\n",
      "Anyscale Embeddings\n",
      "Local Embeddings with HuggingFace\n",
      "Jina Embeddings\n",
      "Langchain Embeddings\n",
      "LLMRails Embeddings\n",
      "MistralAI Embeddings\n",
      "OpenAI Embeddings\n",
      "Text Embedding Inference\n",
      "Together AI Embeddings\n",
      "Voyage Embeddings\n",
      "\n",
      "\n",
      "PromptsToggle child pages in navigation\n",
      "Usage Pattern\n",
      "Completion prompts\n",
      "Chat prompts\n",
      "Accessing/Customizing Prompts within Higher-Level Modules\n",
      "Advanced Prompt Techniques (Variable Mappings, Functions)\n",
      "Prompt Engineering for RAG\n",
      "‚ÄúOptimization by Prompting‚Äù for RAG\n",
      "EmotionPrompt in RAG\n",
      "\n",
      "\n",
      "Using local models\n",
      "Run Llama2 locally\n",
      "\n",
      "\n",
      "EmbeddingsToggle child pages in navigation\n",
      "Azure OpenAI\n",
      "Embeddings with Clarifai\n",
      "CohereAI Embeddings\n",
      "Custom Embeddings\n",
      "Elasticsearch Embeddings\n",
      "Qdrant FastEmbed Embeddings\n",
      "Google PaLM Embeddings\n",
      "Gradient Embeddings\n",
      "Anyscale Embeddings\n",
      "Local Embeddings with HuggingFace\n",
      "Jina Embeddings\n",
      "Langchain Embeddings\n",
      "LLMRails Embeddings\n",
      "MistralAI Embeddings\n",
      "OpenAI Embeddings\n",
      "Text Embedding Inference\n",
      "Together AI Embeddings\n",
      "Voyage Embeddings\n",
      "\n",
      "\n",
      "[Beta] Multi-modal modelsToggle child pages in navigation\n",
      "Multi-Modal LLM using OpenAI GPT-4V model for image reasoning\n",
      "Multi-Modal LLM using Google‚Äôs Gemini model for image understanding and build Retrieval Augmented Generation with LlamaIndex\n",
      "Multi-Modal LLM using Replicate LlaVa, Fuyu 8B, MiniGPT4 models for image reasoning\n",
      "Multi-Modal GPT4V Pydantic Program\n",
      "GPT4-V Experiments with General, Specific questions and Chain Of Thought (COT) Prompting Technique.\n",
      "Retrieval-Augmented Image Captioning\n",
      "Advanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\n",
      "Multi-Modal on PDF‚Äôs with tables.\n",
      "Multi-Modal Retrieval using GPT text embedding and CLIP image embedding for Wikipedia Articles\n",
      "Image to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V\n",
      "Chroma Multi-Modal Demo with LlamaIndex\n",
      "Evaluating Multi-Modal RAG(ListItem)\n",
      "PromptsToggle child pages in navigation\n",
      "Usage Pattern\n",
      "Completion prompts\n",
      "Chat prompts\n",
      "Accessing/Customizing Prompts within Higher-Level Modules\n",
      "Advanced Prompt Techniques (Variable Mappings, Functions)\n",
      "Prompt Engineering for RAG\n",
      "‚ÄúOptimization by Prompting‚Äù for RAG\n",
      "EmotionPrompt in RAG(ListItem)\n",
      "Loading DataToggle child pages in navigation\n",
      "Data Connectors (LlamaHub)Toggle child pages in navigation\n",
      "Usage Pattern\n",
      "Module GuidesToggle child pages in navigation\n",
      "Simple Directory Reader\n",
      "Psychic Reader\n",
      "DeepLake Reader\n",
      "Qdrant Reader\n",
      "Discord Reader\n",
      "MongoDB Reader\n",
      "Chroma Reader\n",
      "MyScale Reader\n",
      "Faiss Reader\n",
      "Obsidian Reader\n",
      "Slack Reader\n",
      "Web Page Reader\n",
      "Pinecone Reader\n",
      "Pathway Reader\n",
      "Mbox Reader\n",
      "MilvusReader\n",
      "Notion Reader\n",
      "Github Repo Reader\n",
      "Google Docs Reader\n",
      "Database Reader\n",
      "Twitter Reader\n",
      "Weaviate Reader\n",
      "Make Reader\n",
      "Deplot Reader Demo\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Documents / NodesToggle child pages in navigation\n",
      "Defining and Customizing DocumentsToggle child pages in navigation\n",
      "Metadata Extraction Usage PatternToggle child pages in navigation\n",
      "Extracting Metadata for Better Document Indexing and Understanding\n",
      "Automated Metadata Extraction for Better Retrieval + Synthesis\n",
      "Entity Metadata Extraction\n",
      "Metadata Extraction and Augmentation w/ Marvin\n",
      "Pydantic Extractor\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Defining and Customizing Nodes\n",
      "Transformations\n",
      "\n",
      "\n",
      "Node Parser Usage PatternToggle child pages in navigation\n",
      "Node Parser Modules\n",
      "\n",
      "\n",
      "Ingestion PipelineToggle child pages in navigation\n",
      "Transformations\n",
      "Advanced Ingestion Pipeline\n",
      "Async Ingestion Pipeline + Metadata Extraction\n",
      "Ingestion Pipeline + Document Management\n",
      "Redis Ingestion Pipeline\n",
      "Building a Live RAG Pipeline over Google Drive Files\n",
      "Parallelizing Ingestion Pipeline(ListItem)\n",
      "IndexingToggle child pages in navigation\n",
      "Using VectorStoreIndexToggle child pages in navigation\n",
      "Metadata ExtractionToggle child pages in navigation\n",
      "Extracting Metadata for Better Document Indexing and Understanding\n",
      "Automated Metadata Extraction for Better Retrieval + Synthesis\n",
      "Entity Metadata Extraction\n",
      "Metadata Extraction and Augmentation w/ Marvin\n",
      "Pydantic Extractor\n",
      "\n",
      "\n",
      "Document Management\n",
      "Vector Store Index usage examples\n",
      "\n",
      "\n",
      "How Each Index Works\n",
      "Module GuidesToggle child pages in navigation\n",
      "VectorStoreIndexToggle child pages in navigation\n",
      "Metadata ExtractionToggle child pages in navigation\n",
      "Extracting Metadata for Better Document Indexing and Understanding\n",
      "Automated Metadata Extraction for Better Retrieval + Synthesis\n",
      "Entity Metadata Extraction\n",
      "Metadata Extraction and Augmentation w/ Marvin\n",
      "Pydantic Extractor\n",
      "\n",
      "\n",
      "Document Management\n",
      "Vector Store Index usage examples\n",
      "\n",
      "\n",
      "Summary Index\n",
      "Tree Index\n",
      "Keyword Table Index\n",
      "Knowledge Graph Index\n",
      "Custom Retriever combining KG Index and VectorStore Index\n",
      "Knowledge Graph Query Engine\n",
      "Knowledge Graph RAG Query Engine\n",
      "REBEL + Knowledge Graph Index\n",
      "REBEL + Wikipedia Filtering\n",
      "SQL Index\n",
      "SQL Query Engine with LlamaIndex + DuckDB\n",
      "Document Summary Index\n",
      "The ObjectIndex Class\n",
      "\n",
      "\n",
      "ComposabilityToggle child pages in navigation\n",
      "Composable Graph Basic\n",
      "Composable Graph with Weaviate\n",
      "Composable Graph(ListItem)\n",
      "StoringToggle child pages in navigation\n",
      "Customizing Storage\n",
      "Persisting & Loading Data\n",
      "Vector StoresToggle child pages in navigation\n",
      "Astra DB\n",
      "Simple Vector Store - Async Index Creation\n",
      "Azure CosmosDB MongoDB Vector Store\n",
      "Cassandra Vector Store\n",
      "Chroma\n",
      "Azure Cognitive Search\n",
      "DashVector Vector Store\n",
      "DeepLake Vector Store\n",
      "DocArray Hnsw Vector Store\n",
      "DocArray InMemory Vector Store\n",
      "Epsilla Vector Store\n",
      "Jaguar Vector Store\n",
      "LanceDB Vector Store\n",
      "Metal Vector Store\n",
      "Milvus Vector Store\n",
      "MyScale Vector Store\n",
      "Elasticsearch Vector Store\n",
      "Faiss Vector Store\n",
      "MongoDB Atlas\n",
      "Neo4j vector store\n",
      "Opensearch Vector Store\n",
      "Pinecone Vector Store\n",
      "Pinecone Vector Store - Hybrid Search\n",
      "pgvecto.rs\n",
      "Postgres Vector Store\n",
      "Redis Vector Store\n",
      "Qdrant Vector Store\n",
      "Qdrant Hybrid Search\n",
      "Rockset Vector Store\n",
      "Simple Vector Store\n",
      "Supabase Vector Store\n",
      "Tair Vector Store\n",
      "Tencent Cloud VectorDB\n",
      "Timescale Vector Store (PostgreSQL)\n",
      "Weaviate Vector Store\n",
      "Weaviate Vector Store - Hybrid Search\n",
      "Zep Vector Store\n",
      "\n",
      "\n",
      "Document Stores\n",
      "Index Stores\n",
      "Key-Value Stores\n",
      "Using Graph StoresToggle child pages in navigation\n",
      "Neo4j Graph Store\n",
      "Nebula Graph Store\n",
      "Knowledge Graph Query Engine\n",
      "Kuzu Graph Store\n",
      "FalkorDB Graph Store\n",
      "\n",
      "\n",
      "Chat Stores(ListItem)\n",
      "QueryingToggle child pages in navigation\n",
      "Query PipelineToggle child pages in navigation\n",
      "Usage Pattern\n",
      "Module Usage\n",
      "Module GuidesToggle child pages in navigation\n",
      "An Introduction to LlamaIndex Query Pipelines\n",
      "Query Pipeline with Async/Parallel Execution\n",
      "Query Pipeline over Pandas DataFrames\n",
      "Query Pipeline for Text-to-SQL\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Query EngineToggle child pages in navigation\n",
      "Usage PatternToggle child pages in navigation\n",
      "Response Modes\n",
      "Streaming\n",
      "\n",
      "\n",
      "Module GuidesToggle child pages in navigation\n",
      "Custom Query Engine\n",
      "Retriever Query Engine\n",
      "Text-to-SQL Guide (Query Engine + Retriever)\n",
      "JSON Query Engine\n",
      "Pandas Query Engine\n",
      "Knowledge Graph Query Engine\n",
      "Knowledge Graph RAG Query Engine\n",
      "Structured Hierarchical Retrieval\n",
      "Router Query Engine\n",
      "Retriever Router Query Engine\n",
      "Joint QA Summary Query Engine\n",
      "Sub Question Query Engine\n",
      "Multi-Step Query Engine\n",
      "SQL Router Query Engine\n",
      "SQL Auto Vector Query Engine\n",
      "SQL Join Query Engine\n",
      "[Beta] Text-to-SQL with PGVector\n",
      "SQL Query Engine with LlamaIndex + DuckDB\n",
      "Retry Query Engine\n",
      "CitationQueryEngine\n",
      "Recursive Retriever + Query Engine Demo\n",
      "Joint Tabular/Semantic QA over Tesla 10K\n",
      "Recursive Retriever + Document Agents\n",
      "Ensemble Query Engine Guide\n",
      "Sub Question Query Engine\n",
      "Recursive Retriever + Document Agents\n",
      "Multi-Document Agents\n",
      "Multi-Document Agents (V1)\n",
      "FLARE Query Engine\n",
      "\n",
      "\n",
      "Supporting ModulesToggle child pages in navigation\n",
      "Query TransformationsToggle child pages in navigation\n",
      "HyDE Query Transform\n",
      "Multi-Step Query Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Chat EngineToggle child pages in navigation\n",
      "Usage Pattern\n",
      "Module GuidesToggle child pages in navigation\n",
      "ReAct Chat Engine\n",
      "OpenAI Chat Engine\n",
      "Condense Question Chat Engine\n",
      "Context Chat Engine\n",
      "Context Plus Condense Chat Engine\n",
      "Simple Chat Engine\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Data AgentsToggle child pages in navigation\n",
      "Usage Pattern\n",
      "Module GuidesToggle child pages in navigation\n",
      "Build your own OpenAI Agent\n",
      "OpenAI Agent with Query Engine Tools\n",
      "Retrieval-Augmented OpenAI Agent\n",
      "OpenAI Agent + Query Engine Experimental Cookbook\n",
      "OpenAI Agent Query Planning\n",
      "Context-Augmented OpenAI Agent\n",
      "Recursive Retriever + Document Agents\n",
      "Multi-Document Agents\n",
      "GPT Builder Demo\n",
      "Single-Turn Multi-Function Calling OpenAI Agents\n",
      "OpenAI Assistant Agent\n",
      "Benchmarking OpenAI Retrieval API (through Assistant Agent)\n",
      "OpenAI Assistant Advanced Retrieval Cookbook\n",
      "ReAct Agent with Query Engine Tools\n",
      "LLMCompiler Agent Cookbook\n",
      "Building a Custom Agent\n",
      "Step-wise, Controllable Agents\n",
      "Controllable Agents for RAG\n",
      "Controllable Agents for RAG\n",
      "\n",
      "\n",
      "ToolsToggle child pages in navigation\n",
      "Usage Pattern\n",
      "LlamaHub Tools Guide\n",
      "\n",
      "\n",
      "Lower-Level Agent API\n",
      "\n",
      "\n",
      "RetrieverToggle child pages in navigation\n",
      "Retriever Modes\n",
      "Retriever ModulesToggle child pages in navigation\n",
      "Define Custom Retriever\n",
      "BM25 Hybrid Retriever\n",
      "Simple Fusion Retriever\n",
      "Reciprocal Rerank Fusion Retriever\n",
      "Auto Merging Retriever\n",
      "Metadata Replacement + Node Sentence Window\n",
      "Auto Retriever (with Pinecone + Arize Phoenix)\n",
      "Auto-Retrieval (with Chroma)\n",
      "Auto-Retrieval (with BagelDB)\n",
      "Structured Hierarchical Retrieval\n",
      "Auto-Retrieval from a Vectara Index\n",
      "Custom Retriever (KG Index and Vector Store Index)\n",
      "Knowledge Graph RAG Retriever\n",
      "Recursive Retriever + Query Engine Demo\n",
      "Recursive Retriever + Node References\n",
      "Recursive Retriever + Node References + Braintrust\n",
      "Router Retriever\n",
      "Ensemble Retrieval Guide\n",
      "Google Generative Language Semantic Retriever\n",
      "Structured Hierarchical Retrieval\n",
      "Google Generative Language Semantic Retriever\n",
      "Vectara Managed Index\n",
      "Managed Index with Zilliz Cloud Pipelines\n",
      "You.com Retriever\n",
      "Text-to-SQL Guide (Query Engine + Retriever)\n",
      "DeepMemory (Activeloop)\n",
      "Pathway Retriever\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Response SynthesizerToggle child pages in navigation\n",
      "Response Synthesis ModulesToggle child pages in navigation\n",
      "Refine\n",
      "Refine with Structured Answer Filtering\n",
      "Tree Summarize\n",
      "Pydantic Tree Summarize\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RoutersToggle child pages in navigation\n",
      "Router Query Engine\n",
      "Retriever Router Query Engine\n",
      "SQL Router Query Engine\n",
      "Router Retriever\n",
      "\n",
      "\n",
      "Node PostprocessorToggle child pages in navigation\n",
      "Node Postprocessor ModulesToggle child pages in navigation\n",
      "Sentence Embedding Optimizer\n",
      "Cohere Rerank\n",
      "LLM Reranker Demonstration (2021 Lyft 10-k)\n",
      "LLM Reranker Demonstration (Great Gatsby)\n",
      "Recency Filtering\n",
      "Time-Weighted Rerank\n",
      "PII Masking\n",
      "Forward/Backward Augmentation\n",
      "Metadata Replacement + Node Sentence Window\n",
      "LongContextReorder\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Structured OutputsToggle child pages in navigation\n",
      "Pydantic ProgramToggle child pages in navigation\n",
      "LLM Pydantic Program\n",
      "OpenAI Pydantic Program\n",
      "Guidance Pydantic Program\n",
      "Guidance for Sub-Question Query Engine\n",
      "DataFrame Structured Data Extraction\n",
      "Evaporate Demo\n",
      "\n",
      "\n",
      "Query Engines + Pydantic OutputsToggle child pages in navigation\n",
      "Query Engine with Pydantic Outputs\n",
      "Pydantic Tree Summarize\n",
      "Download Data\n",
      "\n",
      "\n",
      "Output Parsing ModulesToggle child pages in navigation\n",
      "Guardrails Output Parsing\n",
      "Langchain Output Parsing\n",
      "Guidance Pydantic Program\n",
      "Guidance for Sub-Question Query Engine\n",
      "OpenAI Pydantic Program(ListItem)\n",
      "ObservabilityToggle child pages in navigation\n",
      "Wandb Callback Handler\n",
      "Observability with OpenLLMetry\n",
      "Arize Phoenix Tracing Tutorial\n",
      "OpenInference Callback Handler + Arize Phoenix\n",
      "Evaluating Search and Retrieval with Arize Phoenix\n",
      "Evaluating and Tracking with TruLens\n",
      "Quickstart Guide with LlamaIndex + TruLens\n",
      "Colab\n",
      "HoneyHive LlamaIndex Tracer\n",
      "PromptLayer Handler\n",
      "CallbacksToggle child pages in navigation\n",
      "Token Counting Handler\n",
      "Llama Debug Handler\n",
      "Wandb Callback Handler\n",
      "Aim Callback\n",
      "OpenInference Callback Handler + Arize Phoenix\n",
      "Token Counting - Migration Guide(ListItem)\n",
      "EvaluatingToggle child pages in navigation\n",
      "Usage Pattern (Response Evaluation)\n",
      "Usage Pattern (Retrieval)\n",
      "ModulesToggle child pages in navigation\n",
      "Faithfulness Evaluator\n",
      "Relevancy Evaluator\n",
      "Answer Relevancy and Context Relevancy Evaluations\n",
      "Guideline Evaluator\n",
      "Correctness Evaluator\n",
      "Embedding Similarity Evaluator\n",
      "LlamaIndex + DeepEval Integration\n",
      "QuestionGeneration\n",
      "BatchEvalRunner - Running Multiple Evaluations\n",
      "Evaluating Multi-Modal RAG\n",
      "Retrieval Evaluation\n",
      "\n",
      "\n",
      "Evaluating With LabelledRagDataset‚ÄôsToggle child pages in navigation\n",
      "Benchmarking RAG Pipelines With A LabelledRagDatatset\n",
      "Downloading a LlamaDataset from LlamaHub\n",
      "\n",
      "\n",
      "Contributing A LabelledRagDatasetToggle child pages in navigation\n",
      "LlamaDataset Submission Template Notebook(ListItem)\n",
      "Supporting ModulesToggle child pages in navigation\n",
      "ServiceContext(ListItem)\n",
      "API Reference(Title)\n",
      "API ReferenceToggle child pages in navigation\n",
      "Agents\n",
      "Callbacks\n",
      "Composability\n",
      "Evaluation\n",
      "Example Notebooks\n",
      "Finetuning\n",
      "IndicesToggle child pages in navigation\n",
      "Summary Index\n",
      "Table Index\n",
      "Tree Index\n",
      "Vector Store Index\n",
      "Structured Store Index\n",
      "Knowledge Graph Index\n",
      "Empty Index\n",
      "\n",
      "\n",
      "LLM Predictors\n",
      "LLMsToggle child pages in navigation\n",
      "Anthropic\n",
      "Azure OpenAI\n",
      "HuggingFaceLLM\n",
      "LangChainLLM\n",
      "Gradient Base Model\n",
      "Gradient Model Adapter\n",
      "LiteLLM\n",
      "LlamaCPP\n",
      "OpenAI\n",
      "OpenAILike\n",
      "OpenLLM\n",
      "PaLM\n",
      "Predibase\n",
      "Replicate\n",
      "XOrbits Xinference\n",
      "\n",
      "\n",
      "Memory\n",
      "Multi-Modal LLMs, Vector Stores, Embeddings, Retriever, and Query EngineToggle child pages in navigation\n",
      "OpenAI\n",
      "Replicate\n",
      "\n",
      "\n",
      "Node Postprocessor\n",
      "NodeToggle child pages in navigation\n",
      "BaseComponent\n",
      "BaseNode\n",
      "Document\n",
      "ImageDocument\n",
      "ImageNode\n",
      "IndexNode\n",
      "MetadataMode\n",
      "Node\n",
      "NodeRelationship\n",
      "NodeWithScore\n",
      "ObjectType\n",
      "QueryBundle\n",
      "RelatedNodeInfo\n",
      "TextNode\n",
      "TransformComponent\n",
      "\n",
      "\n",
      "Playground\n",
      "Prompt Templates\n",
      "Querying an IndexToggle child pages in navigation\n",
      "RetrieversToggle child pages in navigation\n",
      "Empty Index Retriever\n",
      "Knowledge Graph Retriever\n",
      "List Retriever\n",
      "Keyword Table Retrievers\n",
      "Tree Retrievers\n",
      "Vector Store Retrievers\n",
      "Transform Retriever\n",
      "\n",
      "\n",
      "Response Synthesizer\n",
      "Query EnginesToggle child pages in navigation\n",
      "Graph Query Engine\n",
      "Multistep Query Engine\n",
      "Retriever Query Engine\n",
      "Transform Query Engine\n",
      "Router Query Engine\n",
      "Retriever Router Query Engine\n",
      "Sub Question Query Engine\n",
      "SQL Join Query Engine\n",
      "Flare Query Engine\n",
      "Citation Query Engine\n",
      "Knowledge Graph Query Engine\n",
      "SQL Query Engine\n",
      "Pandas Query Engine\n",
      "\n",
      "\n",
      "Chat EnginesToggle child pages in navigation\n",
      "Simple Chat Engine\n",
      "Condense Question Chat Engine\n",
      "Condense Plus Context Chat Engine\n",
      "\n",
      "\n",
      "Query Bundle\n",
      "Query Transform\n",
      "\n",
      "\n",
      "Data ConnectorsToggle child pages in navigation\n",
      "download_loader\n",
      "WikipediaReader\n",
      "YoutubeTranscriptReader\n",
      "SimpleDirectoryReader\n",
      "JSONReader\n",
      "SimpleMongoReader\n",
      "NotionPageReader\n",
      "GoogleDocsReader\n",
      "MetalReader\n",
      "DiscordReader\n",
      "SlackReader\n",
      "WeaviateReader\n",
      "PathwayReader\n",
      "PineconeReader\n",
      "PsychicReader\n",
      "QdrantReader\n",
      "MilvusReader\n",
      "ChromaReader\n",
      "DeepLakeReader\n",
      "FaissReader\n",
      "MyScaleReader\n",
      "StringIterableReader\n",
      "SimpleWebPageReader\n",
      "BeautifulSoupWebReader\n",
      "TrafilaturaWebReader\n",
      "RssReader\n",
      "MakeWrapper\n",
      "TwitterTweetReader\n",
      "ObsidianReader\n",
      "GithubRepositoryReader\n",
      "MboxReader\n",
      "ElasticsearchReader\n",
      "SteamshipFileReader\n",
      "ChatGPTRetrievalPluginReader\n",
      "BagelReader\n",
      "HTMLTagReader\n",
      "ReaderConfig\n",
      "PDFReader\n",
      "DashVectorReader\n",
      "\n",
      "\n",
      "Response\n",
      "Service ContextToggle child pages in navigation\n",
      "Embeddings\n",
      "OpenAIEmbedding\n",
      "HuggingFaceEmbedding\n",
      "OptimumEmbedding\n",
      "InstructorEmbedding\n",
      "LangchainEmbedding\n",
      "GoogleUnivSentEncoderEmbedding\n",
      "Node ParserToggle child pages in navigation\n",
      "get_leaf_nodes\n",
      "get_root_nodes\n",
      "TokenTextSplitter\n",
      "SentenceSplitter\n",
      "CodeSplitter\n",
      "SimpleFileNodeParser\n",
      "HTMLNodeParser\n",
      "MarkdownNodeParser\n",
      "JSONNodeParser\n",
      "SentenceWindowNodeParser\n",
      "SemanticSplitterNodeParser\n",
      "NodeParser\n",
      "HierarchicalNodeParser\n",
      "TextSplitter\n",
      "MarkdownElementNodeParser\n",
      "MetadataAwareTextSplitter\n",
      "LangchainNodeParser\n",
      "UnstructuredElementNodeParser\n",
      "SimpleNodeParser\n",
      "\n",
      "\n",
      "PromptHelper\n",
      "LLMsToggle child pages in navigation\n",
      "Anthropic\n",
      "Azure OpenAI\n",
      "HuggingFaceLLM\n",
      "LangChainLLM\n",
      "Gradient Base Model\n",
      "Gradient Model Adapter\n",
      "LiteLLM\n",
      "LlamaCPP\n",
      "OpenAI\n",
      "OpenAILike\n",
      "OpenLLM\n",
      "PaLM\n",
      "Predibase\n",
      "Replicate\n",
      "XOrbits Xinference\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Embeddings\n",
      "OpenAIEmbedding\n",
      "HuggingFaceEmbedding\n",
      "OptimumEmbedding\n",
      "InstructorEmbedding\n",
      "LangchainEmbedding\n",
      "GoogleUnivSentEncoderEmbedding\n",
      "Storage ContextToggle child pages in navigation\n",
      "Document Store\n",
      "Index Store\n",
      "Vector StoreToggle child pages in navigation\n",
      "ElasticsearchStore\n",
      "SimpleVectorStore\n",
      "RedisVectorStore\n",
      "RocksetVectorStore\n",
      "FaissVectorStore\n",
      "PineconeVectorStore\n",
      "WeaviateVectorStore\n",
      "QdrantVectorStore\n",
      "CassandraVectorStore\n",
      "ChromaVectorStore\n",
      "MetalVectorStore\n",
      "OpensearchVectorStore\n",
      "OpensearchVectorClient\n",
      "ChatGPTRetrievalPluginClient\n",
      "MilvusVectorStore\n",
      "DeepLakeVectorStore\n",
      "MyScaleVectorStore\n",
      "LanceDBVectorStore\n",
      "TairVectorStore\n",
      "DocArrayInMemoryVectorStore\n",
      "DocArrayHnswVectorStore\n",
      "SupabaseVectorStore\n",
      "PGVectorStore\n",
      "PGVectoRsStore\n",
      "TimescaleVectorStore\n",
      "ZepVectorStore\n",
      "AwaDBVectorStore\n",
      "BagelVectorStore\n",
      "Neo4jVectorStore\n",
      "CognitiveSearchVectorStore\n",
      "EpsillaVectorStore\n",
      "SingleStoreVectorStore\n",
      "VectorStoreQuery\n",
      "VectorStoreQueryResult\n",
      "MetadataFilters\n",
      "MetadataFilter\n",
      "ExactMatchFilter\n",
      "FilterCondition\n",
      "FilterOperator\n",
      "DashVectorStore\n",
      "TencentVectorDB\n",
      "AstraDBVectorStore\n",
      "AzureCosmosDBMongoDBVectorSearch\n",
      "LanternVectorStore\n",
      "MongoDBAtlasVectorSearch\n",
      "\n",
      "\n",
      "KV Storage\n",
      "Loading Indices\n",
      "\n",
      "\n",
      "Structured Index Configuration(ListItem)\n",
      "Community(Title)\n",
      "IntegrationsToggle child pages in navigation\n",
      "Llama Packs ü¶ôüì¶Toggle child pages in navigation\n",
      "Llama Packs Example\n",
      "Llama Pack - Resume Screener üìÑ\n",
      "Ollama Llama Pack Example\n",
      "\n",
      "\n",
      "ObservabilityToggle child pages in navigation\n",
      "Wandb Callback Handler\n",
      "Observability with OpenLLMetry\n",
      "Arize Phoenix Tracing Tutorial\n",
      "OpenInference Callback Handler + Arize Phoenix\n",
      "Evaluating Search and Retrieval with Arize Phoenix\n",
      "Evaluating and Tracking with TruLens\n",
      "Quickstart Guide with LlamaIndex + TruLens\n",
      "Colab\n",
      "HoneyHive LlamaIndex Tracer\n",
      "PromptLayer Handler\n",
      "CallbacksToggle child pages in navigation\n",
      "Token Counting Handler\n",
      "Llama Debug Handler\n",
      "Wandb Callback Handler\n",
      "Aim Callback\n",
      "OpenInference Callback Handler + Arize Phoenix\n",
      "Token Counting - Migration Guide\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tracing with Graphsignal\n",
      "Evaluating and Tracking with TruLens\n",
      "Unit Testing LLMs With DeepEval\n",
      "Guidance\n",
      "LM Format Enforcer\n",
      "Guardrails\n",
      "OpenAI Function Calling\n",
      "Using Vector StoresToggle child pages in navigation\n",
      "Astra DB\n",
      "Simple Vector Store - Async Index Creation\n",
      "Azure CosmosDB MongoDB Vector Store\n",
      "Cassandra Vector Store\n",
      "Chroma\n",
      "Azure Cognitive Search\n",
      "DashVector Vector Store\n",
      "DeepLake Vector Store\n",
      "DocArray Hnsw Vector Store\n",
      "DocArray InMemory Vector Store\n",
      "Epsilla Vector Store\n",
      "LanceDB Vector Store\n",
      "Metal Vector Store\n",
      "Milvus Vector Store\n",
      "MyScale Vector Store\n",
      "Elasticsearch Vector Store\n",
      "Faiss Vector Store\n",
      "MongoDB Atlas\n",
      "Neo4j vector store\n",
      "Opensearch Vector Store\n",
      "Pinecone Vector Store\n",
      "Pinecone Vector Store - Hybrid Search\n",
      "pgvecto.rs\n",
      "Postgres Vector Store\n",
      "Redis Vector Store\n",
      "Qdrant Vector Store\n",
      "Qdrant Hybrid Search\n",
      "Rockset Vector Store\n",
      "Simple Vector Store\n",
      "Supabase Vector Store\n",
      "Tair Vector Store\n",
      "Tencent Cloud VectorDB\n",
      "Timescale Vector Store (PostgreSQL)\n",
      "Weaviate Vector Store\n",
      "Weaviate Vector Store - Hybrid Search\n",
      "Zep Vector Store\n",
      "\n",
      "\n",
      "Using Graph StoresToggle child pages in navigation\n",
      "Neo4j Graph Store\n",
      "Nebula Graph Store\n",
      "Knowledge Graph Query Engine\n",
      "Kuzu Graph Store\n",
      "FalkorDB Graph Store\n",
      "\n",
      "\n",
      "Using Managed IndicesToggle child pages in navigation\n",
      "Google Generative Language Semantic Retriever\n",
      "Vectara Managed Index\n",
      "Auto-Retrieval from a Vectara Index\n",
      "Managed Index with Zilliz Cloud Pipelines\n",
      "\n",
      "\n",
      "Using with Langchain ü¶úüîó\n",
      "Streamlit\n",
      "Chainlit\n",
      "LlamaIndex + Ray\n",
      "ChatGPT Plugin Integrations\n",
      "Poe\n",
      "Airbyte\n",
      "Fleet Context Embeddings - Building a Hybrid Search Engine for the Llamaindex Library(ListItem)\n",
      "Frequently Asked Questions (FAQ)Toggle child pages in navigation\n",
      "Large Language Models\n",
      "Embeddings\n",
      "Vector Database\n",
      "Query Engines\n",
      "Chat Engines\n",
      "Documents and Nodes(ListItem)\n",
      "Full-Stack ProjectsToggle child pages in navigation\n",
      "create-llama Blog\n",
      "create-llama Repo\n",
      "create-llama Additional Templates\n",
      "SEC Insights App\n",
      "SEC Insights Repo\n",
      "Chat LlamaIndex App\n",
      "Chat LlamaIndex Repo\n",
      "RAGs Repo(ListItem)\n",
      "Contributing(Title)\n",
      "Contributing to LlamaIndex(ListItem)\n",
      "Documentation Guide(ListItem)\n",
      "Changes(Title)\n",
      "ChangeLog(ListItem)\n",
      "Deprecated Terms(ListItem)\n",
      "Back to top(NarrativeText)\n",
      "Toggle Light / Dark / Auto color theme(Title)\n",
      "Toggle table of contents sidebar(Title)\n",
      "Installation and SetupÔÉÅ(Title)\n",
      "Installation from PipÔÉÅ(Title)\n",
      "Install from pip:(Title)\n",
      "pip(Title)\n",
      "install(Title)\n",
      "llama(Title)\n",
      "index(Title)\n",
      "NOTE: LlamaIndex may download and store local files for various packages (NLTK, HuggingFace, ‚Ä¶). Use the environment variable ‚ÄúLLAMA_INDEX_CACHE_DIR‚Äù to control where these files are saved.(NarrativeText)\n",
      "If you prefer to install from source, see below.(NarrativeText)\n",
      "Important: OpenAI Environment SetupÔÉÅ(Title)\n",
      "By default, we use the OpenAI gpt-3.5-turbo model for text generation and text-embedding-ada-002 for retrieval and embeddings. In order to use this, you must have an OPENAI_API_KEY set up as an environment variable.\n",
      "You can obtain an API key by logging into your OpenAI account and and creating a new API key.(NarrativeText)\n",
      "Tip(Title)\n",
      "You can also use one of many other available LLMs. You may\n",
      "need additional environment keys + tokens setup depending on the LLM provider.(NarrativeText)\n",
      "Local Model SetupÔÉÅ(Title)\n",
      "If you don‚Äôt wish to use OpenAI, consider setting up a local LLM and embedding model in the service context.(NarrativeText)\n",
      "A full guide to using and configuring LLMs available here.(NarrativeText)\n",
      "A full guide to using and configuring embedding models is available here.(NarrativeText)\n",
      "Installation from SourceÔÉÅ(Title)\n",
      "Git clone this repository: git clone https://github.com/jerryjliu/llama_index.git. Then do the following:(NarrativeText)\n",
      "Install poetry - this will help you manage package dependencies(ListItem)\n",
      "poetry shell - this command creates a virtual environment, which keeps installed packages contained to this project(ListItem)\n",
      "poetry install - this will install the core package requirements(ListItem)\n",
      "(Optional) poetry install --with dev,docs - this will install all dependencies needed for most local development(ListItem)\n",
      "Optional DependenciesÔÉÅ(Title)\n",
      "By default LlamaIndex installs a core set of dependencies; we also provide a convenient way to install commonly-required optional dependencies. These are currently in three sets:(NarrativeText)\n",
      "pip install llama-index[local_models] installs tools useful for private LLMs, local inference, and HuggingFace models(ListItem)\n",
      "pip install llama-index[postgres] is useful if you are working with Postgres, PGVector or Supabase(ListItem)\n",
      "pip install llama-index[query_tools] gives you tools for hybrid search, structured outputs, and node post-processing(ListItem)\n",
      "Next\n",
      "                \n",
      "                How to read these docs(NarrativeText)\n",
      "Previous\n",
      "                \n",
      "                \n",
      "                Home(UncategorizedText)\n",
      "Copyright ¬© 2023, Jerry Liu\n",
      "            \n",
      "            Made with(UncategorizedText)\n",
      "Sphinx and(Title)\n",
      "@pradyunsg's(Title)\n",
      "Furo(Title)\n",
      "On this page(Title)\n",
      "Installation and Setup\n",
      "Installation from Pip\n",
      "Important: OpenAI Environment Setup\n",
      "Local Model Setup\n",
      "Installation from Source\n",
      "Optional Dependencies(ListItem)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(output_filename) as f:\n",
    "    index_jsons = json.load(f)\n",
    "\n",
    "content = \"\"\n",
    "for i, item in enumerate(index_jsons):\n",
    "    # if i == 40:\n",
    "    #     break\n",
    "    content +=  f\"{item['text']}({item['type']})\\n\"\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'element_id': '88d3b4fc28fde367a8773eb09aee40f9',\n",
       " 'metadata': {'category_depth': 1,\n",
       "  'file_directory': '/Users/sasha/github/LlamaIndex/llama_index/docs/_build/html',\n",
       "  'filename': 'index.html',\n",
       "  'filetype': 'text/html',\n",
       "  'languages': ['eng'],\n",
       "  'last_modified': '2024-01-15T15:46:27',\n",
       "  'link_texts': ['Prompts',\n",
       "   None,\n",
       "   'Usage Pattern',\n",
       "   'Completion prompts',\n",
       "   'Chat prompts',\n",
       "   'Accessing/Customizing Prompts within Higher-Level Modules',\n",
       "   'Advanced Prompt Techniques (Variable Mappings, Functions)',\n",
       "   'Prompt Engineering for RAG',\n",
       "   '‚ÄúOptimization by Prompting‚Äù for RAG',\n",
       "   'EmotionPrompt in RAG'],\n",
       "  'link_urls': ['module_guides/models/prompts.html',\n",
       "   '#svg-arrow-right',\n",
       "   'module_guides/models/prompts/usage_pattern.html',\n",
       "   'examples/customization/prompts/completion_prompts.html',\n",
       "   'examples/customization/prompts/chat_prompts.html',\n",
       "   'examples/prompts/prompt_mixin.html',\n",
       "   'examples/prompts/advanced_prompts.html',\n",
       "   'examples/prompts/prompts_rag.html',\n",
       "   'examples/prompts/prompt_optimization.html',\n",
       "   'examples/prompts/emotion_prompt.html'],\n",
       "  'page_number': 1,\n",
       "  'parent_id': 'db607626333a84eacc789d95e9a8fcf0'},\n",
       " 'text': 'PromptsToggle child pages in navigation\\nUsage Pattern\\nCompletion prompts\\nChat prompts\\nAccessing/Customizing Prompts within Higher-Level Modules\\nAdvanced Prompt Techniques (Variable Mappings, Functions)\\nPrompt Engineering for RAG\\n‚ÄúOptimization by Prompting‚Äù for RAG\\nEmotionPrompt in RAG',\n",
       " 'type': 'ListItem'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def generate_file(input_filename, output_filename):\n",
    "    elements = partition(filename=input_filename)\n",
    "    elements_to_json(elements, filename=output_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
